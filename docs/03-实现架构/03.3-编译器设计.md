# ç¼–è¯‘å™¨è®¾è®¡ï¼ˆCompiler Designï¼‰

> **é€‚ç”¨ç‰ˆæœ¬**: OPA v0.42+ (ç°ä»£ç¼–è¯‘æ¶æ„) | æ¨è v0.68+  
> **å®ç°è¯­è¨€**: Go 1.20+  
> **æºç **: `github.com/open-policy-agent/opa/compile`  
> **æœ€åéªŒè¯**: 2025-10-21  
> **æ–‡æ¡£çŠ¶æ€**: âœ… å·²éªŒè¯  
> **å‚è€ƒ**: <https://github.com/open-policy-agent/opa>

---

## ğŸ—ï¸ ç¼–è¯‘å™¨æ¶æ„æ¦‚è§ˆ

> **æœ¬æ–‡æ¡£ä»·å€¼**:
>
> - âœ… æ·±å…¥ç†è§£Regoåˆ°WASM/Nativeçš„å®Œæ•´ç¼–è¯‘æµç¨‹
> - âœ… æŒæ¡ç¼–è¯‘ä¼˜åŒ–æŠ€æœ¯ï¼ˆå†…è”ã€æ­»ä»£ç æ¶ˆé™¤ï¼‰
> - âœ… ä¸ºOPAç¼–è¯‘å™¨è´¡çŒ®ä»£ç 
> - âš ï¸ é«˜åº¦æŠ€æœ¯æ€§ï¼Œé€‚åˆç¼–è¯‘å™¨ä¸“ä¸šäººå‘˜
>
> **ç¼–è¯‘æµç¨‹æ¦‚è§ˆ**:
>
> ```text
> Regoæºç  â†’ è¯æ³•åˆ†æ â†’ è¯­æ³•è§£æ â†’ AST
>           â†“
>       è¯­ä¹‰åˆ†æ/ç±»å‹æ£€æŸ¥ â†’ ä¼˜åŒ– â†’ IR
>           â†“
>       ä»£ç ç”Ÿæˆ â†’ WASM/Native
> ```
>
> ç›¸å…³: [è¯æ³•ä¸è§£æ](03.1-è¯æ³•åˆ†æä¸è¯­æ³•è§£æ.md) | [ASTä¸IR](03.2-ASTä¸IR.md)

---

## ç›®å½•

- [ç¼–è¯‘å™¨è®¾è®¡ï¼ˆCompiler Designï¼‰](#ç¼–è¯‘å™¨è®¾è®¡compiler-design)
  - [ğŸ—ï¸ ç¼–è¯‘å™¨æ¶æ„æ¦‚è§ˆ](#ï¸-ç¼–è¯‘å™¨æ¶æ„æ¦‚è§ˆ)
  - [ç›®å½•](#ç›®å½•)
  - [1. ç¼–è¯‘å™¨æ¦‚è¿°](#1-ç¼–è¯‘å™¨æ¦‚è¿°)
    - [1.1 ç¼–è¯‘å™¨æ¶æ„](#11-ç¼–è¯‘å™¨æ¶æ„)
    - [1.2 ç¼–è¯‘é˜¶æ®µ](#12-ç¼–è¯‘é˜¶æ®µ)
    - [1.3 è®¾è®¡ç›®æ ‡](#13-è®¾è®¡ç›®æ ‡)
  - [2. è¯æ³•åˆ†æï¼ˆLexingï¼‰](#2-è¯æ³•åˆ†ælexing)
    - [2.1 Tokenå®šä¹‰](#21-tokenå®šä¹‰)
    - [2.2 è¯æ³•åˆ†æå™¨å®ç°](#22-è¯æ³•åˆ†æå™¨å®ç°)
    - [2.3 é”™è¯¯å¤„ç†](#23-é”™è¯¯å¤„ç†)
  - [3. è¯­æ³•åˆ†æï¼ˆParsingï¼‰](#3-è¯­æ³•åˆ†æparsing)
    - [3.1 æ–‡æ³•å®šä¹‰](#31-æ–‡æ³•å®šä¹‰)
    - [3.2 é€’å½’ä¸‹é™è§£æ](#32-é€’å½’ä¸‹é™è§£æ)
    - [3.3 è¿ç®—ç¬¦ä¼˜å…ˆçº§](#33-è¿ç®—ç¬¦ä¼˜å…ˆçº§)
  - [4. è¯­ä¹‰åˆ†æ](#4-è¯­ä¹‰åˆ†æ)
    - [4.1 ä½œç”¨åŸŸåˆ†æ](#41-ä½œç”¨åŸŸåˆ†æ)
    - [4.2 ç±»å‹æ£€æŸ¥](#42-ç±»å‹æ£€æŸ¥)
    - [4.3 å®‰å…¨æ€§æ£€æŸ¥](#43-å®‰å…¨æ€§æ£€æŸ¥)
  - [5. ä¸­é—´ä»£ç ç”Ÿæˆ](#5-ä¸­é—´ä»£ç ç”Ÿæˆ)
    - [5.1 IRç”Ÿæˆç­–ç•¥](#51-irç”Ÿæˆç­–ç•¥)
    - [5.2 æ§åˆ¶æµå›¾æ„å»º](#52-æ§åˆ¶æµå›¾æ„å»º)
    - [5.3 SSAè½¬æ¢](#53-ssaè½¬æ¢)
  - [6. ä¼˜åŒ–](#6-ä¼˜åŒ–)
    - [6.1 å±€éƒ¨ä¼˜åŒ–](#61-å±€éƒ¨ä¼˜åŒ–)
    - [6.2 å…¨å±€ä¼˜åŒ–](#62-å…¨å±€ä¼˜åŒ–)
    - [6.3 æ•°æ®æµåˆ†æ](#63-æ•°æ®æµåˆ†æ)
  - [7. ä»£ç ç”Ÿæˆ](#7-ä»£ç ç”Ÿæˆ)
    - [7.1 å­—èŠ‚ç ç”Ÿæˆ](#71-å­—èŠ‚ç ç”Ÿæˆ)
    - [7.2 WASMç”Ÿæˆ](#72-wasmç”Ÿæˆ)
    - [7.3 åŸç”Ÿä»£ç ç”Ÿæˆ](#73-åŸç”Ÿä»£ç ç”Ÿæˆ)
  - [8. é”™è¯¯å¤„ç†ä¸æ¢å¤](#8-é”™è¯¯å¤„ç†ä¸æ¢å¤)
    - [8.1 é”™è¯¯åˆ†ç±»](#81-é”™è¯¯åˆ†ç±»)
    - [8.2 é”™è¯¯æ¢å¤ç­–ç•¥](#82-é”™è¯¯æ¢å¤ç­–ç•¥)
    - [8.3 è¯Šæ–­ä¿¡æ¯](#83-è¯Šæ–­ä¿¡æ¯)
  - [9. ç¼–è¯‘å™¨ä¼˜åŒ–æŠ€æœ¯](#9-ç¼–è¯‘å™¨ä¼˜åŒ–æŠ€æœ¯)
    - [9.1 éƒ¨åˆ†æ±‚å€¼](#91-éƒ¨åˆ†æ±‚å€¼)
    - [9.2 ç´¢å¼•æ„å»º](#92-ç´¢å¼•æ„å»º)
    - [9.3 è§„åˆ™é‡å†™](#93-è§„åˆ™é‡å†™)
  - [10. å®è·µæ¡ˆä¾‹](#10-å®è·µæ¡ˆä¾‹)
    - [10.1 ç¼–è¯‘ç®€å•ç­–ç•¥](#101-ç¼–è¯‘ç®€å•ç­–ç•¥)
    - [10.2 ç¼–è¯‘å¤æ‚æ¨å¯¼](#102-ç¼–è¯‘å¤æ‚æ¨å¯¼)
    - [10.3 ç¼–è¯‘é€’å½’è§„åˆ™](#103-ç¼–è¯‘é€’å½’è§„åˆ™)
  - [é™„å½•Aï¼šç¼–è¯‘å™¨å®ç°ä»£ç ](#é™„å½•aç¼–è¯‘å™¨å®ç°ä»£ç )
  - [é™„å½•Bï¼šä¼˜åŒ–Passæ¸…å•](#é™„å½•bä¼˜åŒ–passæ¸…å•)

---

## 1. ç¼–è¯‘å™¨æ¦‚è¿°

### 1.1 ç¼–è¯‘å™¨æ¶æ„

**OPAç¼–è¯‘å™¨ç»“æ„**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Compiler Frontend              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Lexer â†’ Parser â†’ AST Builder            â”‚
â”‚    â†“                                     â”‚
â”‚  Semantic Analyzer                       â”‚
â”‚    â”œâ”€â”€ Scope Resolution                  â”‚
â”‚    â”œâ”€â”€ Type Checking                     â”‚
â”‚    â””â”€â”€ Safety Checking                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Compiler Middle-end              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  IR Generator                            â”‚
â”‚    â†“                                     â”‚
â”‚  Optimizer                               â”‚
â”‚    â”œâ”€â”€ Constant Folding                  â”‚
â”‚    â”œâ”€â”€ Dead Code Elimination             â”‚
â”‚    â”œâ”€â”€ Inlining                          â”‚
â”‚    â””â”€â”€ Partial Evaluation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Compiler Backend               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Code Generator                          â”‚
â”‚    â”œâ”€â”€ Bytecode Generation               â”‚
â”‚    â”œâ”€â”€ WASM Generation                   â”‚
â”‚    â””â”€â”€ Native Code Generation (JIT)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 ç¼–è¯‘é˜¶æ®µ

**å¤šPassç¼–è¯‘**ï¼š

```text
Pass 1: è¯æ³•ä¸è¯­æ³•åˆ†æ
  Input:  Rego source code
  Output: AST
  Time:   O(n) where n = source size

Pass 2: è¯­ä¹‰åˆ†æ
  Input:  AST
  Output: Annotated AST
  Time:   O(n) where n = AST size

Pass 3: IRç”Ÿæˆ
  Input:  Annotated AST
  Output: IR
  Time:   O(n)

Pass 4: ä¼˜åŒ–
  Input:  IR
  Output: Optimized IR
  Time:   O(n log n) ~ O(nÂ²) depending on optimizations

Pass 5: ä»£ç ç”Ÿæˆ
  Input:  Optimized IR
  Output: Executable code
  Time:   O(n)
```

### 1.3 è®¾è®¡ç›®æ ‡

**æ ¸å¿ƒè®¾è®¡ç›®æ ‡**ï¼š

```text
1. æ­£ç¡®æ€§ï¼ˆCorrectnessï¼‰
   â””â”€â”€ ä¸¥æ ¼éµå¾ªRegoè¯­ä¹‰è§„èŒƒ

2. æ€§èƒ½ï¼ˆPerformanceï¼‰
   â”œâ”€â”€ å¿«é€Ÿç¼–è¯‘ï¼ˆ< 100ms forå…¸å‹ç­–ç•¥ï¼‰
   â””â”€â”€ é«˜æ•ˆæ‰§è¡Œï¼ˆmillion decisions/secï¼‰

3. å¯è°ƒè¯•æ€§ï¼ˆDebuggabilityï¼‰
   â”œâ”€â”€ ç²¾ç¡®çš„é”™è¯¯ä¿¡æ¯
   â”œâ”€â”€ æºç æ˜ å°„
   â””â”€â”€ ç¬¦å·ä¿¡æ¯ä¿ç•™

4. å¯æ‰©å±•æ€§ï¼ˆExtensibilityï¼‰
   â”œâ”€â”€ æ”¯æŒæ–°è¯­è¨€ç‰¹æ€§
   â”œâ”€â”€ å¯æ’æ‹”ä¼˜åŒ–Pass
   â””â”€â”€ å¤šåç«¯æ”¯æŒ
```

---

## 2. è¯æ³•åˆ†æï¼ˆLexingï¼‰

### 2.1 Tokenå®šä¹‰

**Tokenç±»å‹**ï¼š

```go
type TokenType int

const (
    // å…³é”®å­—
    PACKAGE TokenType = iota
    IMPORT
    AS
    DEFAULT
    IF
    ELSE
    SOME
    IN
    EVERY
    NOT
    
    // å­—é¢é‡
    IDENT      // æ ‡è¯†ç¬¦
    NUMBER     // 123, 45.67
    STRING     // "hello"
    TRUE
    FALSE
    NULL
    
    // è¿ç®—ç¬¦
    ASSIGN     // :=
    EQ         // =
    NEQ        // !=
    LT         // <
    LTE        // <=
    GT         // >
    GTE        // >=
    PLUS       // +
    MINUS      // -
    MULTIPLY   // *
    DIVIDE     // /
    
    // åˆ†éš”ç¬¦
    LPAREN     // (
    RPAREN     // )
    LBRACK     // [
    RBRACK     // ]
    LBRACE     // {
    RBRACE     // }
    SEMICOLON  // ;
    DOT        // .
    COMMA      // ,
    
    // ç‰¹æ®Š
    EOF
    ILLEGAL
)
```

### 2.2 è¯æ³•åˆ†æå™¨å®ç°

**Lexerç»“æ„**ï¼š

```go
package compiler

import (
    "unicode"
    "unicode/utf8"
)

type Lexer struct {
    input   string
    pos     int    // å½“å‰ä½ç½®
    readPos int    // ä¸‹ä¸€ä¸ªä½ç½®
    ch      rune   // å½“å‰å­—ç¬¦
    line    int
    column  int
}

func NewLexer(input string) *Lexer {
    l := &Lexer{
        input:  input,
        line:   1,
        column: 0,
    }
    l.readChar()
    return l
}

func (l *Lexer) readChar() {
    if l.readPos >= len(l.input) {
        l.ch = 0  // EOF
    } else {
        l.ch, _ = utf8.DecodeRuneInString(l.input[l.readPos:])
    }
    l.pos = l.readPos
    l.readPos++
    l.column++
    
    if l.ch == '\n' {
        l.line++
        l.column = 0
    }
}

func (l *Lexer) NextToken() Token {
    l.skipWhitespace()
    
    var tok Token
    tok.Line = l.line
    tok.Column = l.column
    
    switch l.ch {
    case '=':
        if l.peekChar() == '=' {
            l.readChar()
            tok.Type = EQ
            tok.Literal = "=="
        } else {
            tok.Type = ASSIGN
            tok.Literal = "="
        }
    case '+':
        tok.Type = PLUS
        tok.Literal = string(l.ch)
    case '-':
        tok.Type = MINUS
        tok.Literal = string(l.ch)
    case '(':
        tok.Type = LPAREN
        tok.Literal = string(l.ch)
    case ')':
        tok.Type = RPAREN
        tok.Literal = string(l.ch)
    case '"':
        tok.Type = STRING
        tok.Literal = l.readString()
    case 0:
        tok.Type = EOF
        tok.Literal = ""
    default:
        if isLetter(l.ch) {
            tok.Literal = l.readIdentifier()
            tok.Type = lookupIdent(tok.Literal)
            return tok
        } else if isDigit(l.ch) {
            tok.Type = NUMBER
            tok.Literal = l.readNumber()
            return tok
        } else {
            tok.Type = ILLEGAL
            tok.Literal = string(l.ch)
        }
    }
    
    l.readChar()
    return tok
}

func (l *Lexer) readIdentifier() string {
    position := l.pos
    for isLetter(l.ch) || isDigit(l.ch) || l.ch == '_' {
        l.readChar()
    }
    return l.input[position:l.pos]
}

func (l *Lexer) readNumber() string {
    position := l.pos
    for isDigit(l.ch) {
        l.readChar()
    }
    if l.ch == '.' {
        l.readChar()
        for isDigit(l.ch) {
            l.readChar()
        }
    }
    return l.input[position:l.pos]
}

func (l *Lexer) readString() string {
    position := l.pos + 1
    for {
        l.readChar()
        if l.ch == '"' || l.ch == 0 {
            break
        }
        if l.ch == '\\' {
            l.readChar()  // Skip escaped character
        }
    }
    return l.input[position:l.pos]
}
```

### 2.3 é”™è¯¯å¤„ç†

**è¯æ³•é”™è¯¯**ï¼š

```go
type LexError struct {
    Line    int
    Column  int
    Message string
}

func (l *Lexer) error(msg string) *LexError {
    return &LexError{
        Line:    l.line,
        Column:  l.column,
        Message: msg,
    }
}

// ç¤ºä¾‹ï¼šæœªé—­åˆçš„å­—ç¬¦ä¸²
func (l *Lexer) readString() (string, error) {
    position := l.pos + 1
    for {
        l.readChar()
        if l.ch == 0 {
            return "", l.error("æœªé—­åˆçš„å­—ç¬¦ä¸²")
        }
        if l.ch == '"' {
            break
        }
    }
    return l.input[position:l.pos], nil
}
```

---

## 3. è¯­æ³•åˆ†æï¼ˆParsingï¼‰

### 3.1 æ–‡æ³•å®šä¹‰

**Regoæ–‡æ³•ï¼ˆç®€åŒ–EBNFï¼‰**ï¼š

```ebnf
module       = package imports rules

package      = "package" ref

imports      = { import }
import       = "import" ref [ "as" var ]

rules        = { rule }
rule         = [ "default" ] head [ "if" "{" body "}" ] [ else_clause ]

head         = ref [ "=" term ] [ "{" term "}" ]

body         = expr { ( ";" | newline ) expr }

expr         = term | expr infix_op term | prefix_op expr

term         = ref | var | scalar | array | object | set | comprehension | call

infix_op     = "==" | "!=" | "<" | "<=" | ">" | ">=" | "+" | "-" | "*" | "/" | "&" | "|"
prefix_op    = "not"

ref          = var { ref_arg }
ref_arg      = dot_arg | bracket_arg
dot_arg      = "." var
bracket_arg  = "[" term "]"

array        = "[" [ term { "," term } ] "]"
object       = "{" [ object_item { "," object_item } ] "}"
object_item  = term ":" term

set          = "{" term { "," term } "}"
```

### 3.2 é€’å½’ä¸‹é™è§£æ

**Parserå®ç°**ï¼š

```go
type Parser struct {
    lexer    *Lexer
    curToken Token
    peekToken Token
    errors   []error
}

func NewParser(lexer *Lexer) *Parser {
    p := &Parser{lexer: lexer}
    p.nextToken()
    p.nextToken()
    return p
}

func (p *Parser) ParseModule() (*ast.Module, error) {
    module := &ast.Module{}
    
    // è§£æpackage
    if !p.expectToken(PACKAGE) {
        return nil, p.error("expected 'package'")
    }
    module.Package = p.parsePackage()
    
    // è§£æimports
    for p.curTokenIs(IMPORT) {
        module.Imports = append(module.Imports, p.parseImport())
    }
    
    // è§£ærules
    for !p.curTokenIs(EOF) {
        rule := p.parseRule()
        if rule != nil {
            module.Rules = append(module.Rules, rule)
        }
        p.nextToken()
    }
    
    if len(p.errors) > 0 {
        return nil, fmt.Errorf("parsing errors: %v", p.errors)
    }
    
    return module, nil
}

func (p *Parser) parseRule() *ast.Rule {
    rule := &ast.Rule{}
    
    // Defaultè§„åˆ™
    if p.curTokenIs(DEFAULT) {
        rule.Default = true
        p.nextToken()
    }
    
    // è§£æHead
    rule.Head = p.parseHead()
    
    // è§£æBody (if { ... })
    if p.curTokenIs(IF) {
        p.nextToken()
        p.expectToken(LBRACE)
        rule.Body = p.parseBody()
        p.expectToken(RBRACE)
    }
    
    // Elseå­å¥
    if p.curTokenIs(ELSE) {
        rule.Else = p.parseElse()
    }
    
    return rule
}

func (p *Parser) parseExpr() ast.Expr {
    return p.parseInfixExpr(p.parsePrefixExpr(), 0)
}

func (p *Parser) parseInfixExpr(left ast.Expr, precedence int) ast.Expr {
    for p.peekToken.Type.IsInfix() && p.peekPrecedence() > precedence {
        p.nextToken()
        op := p.curToken
        p.nextToken()
        right := p.parsePrefixExpr()
        right = p.parseInfixExpr(right, p.curPrecedence())
        
        left = &ast.InfixExpr{
            Left:     left,
            Operator: op.Literal,
            Right:    right,
        }
    }
    return left
}
```

### 3.3 è¿ç®—ç¬¦ä¼˜å…ˆçº§

**ä¼˜å…ˆçº§è¡¨**ï¼š

```go
const (
    _ int = iota
    LOWEST
    LOGIC_OR      // |
    LOGIC_AND     // &
    EQUALS        // ==, !=
    LESSGREATER   // <, <=, >, >=
    SUM           // +, -
    PRODUCT       // *, /
    PREFIX        // not
    CALL          // function()
)

var precedences = map[TokenType]int{
    OR:       LOGIC_OR,
    AND:      LOGIC_AND,
    EQ:       EQUALS,
    NEQ:      EQUALS,
    LT:       LESSGREATER,
    LTE:      LESSGREATER,
    GT:       LESSGREATER,
    GTE:      LESSGREATER,
    PLUS:     SUM,
    MINUS:    SUM,
    MULTIPLY: PRODUCT,
    DIVIDE:   PRODUCT,
    NOT:      PREFIX,
}
```

---

## 4. è¯­ä¹‰åˆ†æ

### 4.1 ä½œç”¨åŸŸåˆ†æ

**ä½œç”¨åŸŸè§£æå™¨**ï¼š

```go
type ScopeAnalyzer struct {
    scopes  []*Scope
    errors  []error
}

type Scope struct {
    parent  *Scope
    symbols map[string]*Symbol
}

func (sa *ScopeAnalyzer) EnterScope() {
    scope := &Scope{
        parent:  sa.currentScope(),
        symbols: make(map[string]*Symbol),
    }
    sa.scopes = append(sa.scopes, scope)
}

func (sa *ScopeAnalyzer) ExitScope() {
    sa.scopes = sa.scopes[:len(sa.scopes)-1]
}

func (sa *ScopeAnalyzer) Declare(name string, symbol *Symbol) error {
    scope := sa.currentScope()
    if _, exists := scope.symbols[name]; exists {
        return fmt.Errorf("é‡å¤å®šä¹‰: %s", name)
    }
    scope.symbols[name] = symbol
    return nil
}

func (sa *ScopeAnalyzer) Resolve(name string) (*Symbol, error) {
    for scope := sa.currentScope(); scope != nil; scope = scope.parent {
        if symbol, ok := scope.symbols[name]; ok {
            return symbol, nil
        }
    }
    return nil, fmt.Errorf("æœªå®šä¹‰çš„å˜é‡: %s", name)
}
```

### 4.2 ç±»å‹æ£€æŸ¥

**ç±»å‹æ£€æŸ¥å™¨**ï¼š

```go
type TypeChecker struct {
    env    *TypeEnvironment
    errors []error
}

func (tc *TypeChecker) Check(module *ast.Module) error {
    for _, rule := range module.Rules {
        tc.checkRule(rule)
    }
    return tc.wrapErrors()
}

func (tc *TypeChecker) checkRule(rule *ast.Rule) {
    // æ¨æ–­Headç±»å‹
    headType := tc.inferType(rule.Head.Value)
    
    // æ£€æŸ¥Body
    for _, expr := range rule.Body {
        exprType := tc.inferType(expr)
        
        // Bodyè¡¨è¾¾å¼å¿…é¡»è¿”å›å¸ƒå°”å€¼
        if !exprType.AssignableTo(TypeBoolean) {
            tc.errors = append(tc.errors,
                fmt.Errorf("è¡¨è¾¾å¼å¿…é¡»è¿”å›å¸ƒå°”å€¼ï¼Œå®é™…: %v", exprType))
        }
    }
    
    // æ£€æŸ¥Defaultå€¼ç±»å‹
    if rule.Default && rule.Head.Value != nil {
        defaultType := tc.inferType(rule.Head.Value)
        if !defaultType.AssignableTo(headType) {
            tc.errors = append(tc.errors,
                fmt.Errorf("defaultå€¼ç±»å‹ä¸åŒ¹é…"))
        }
    }
}

func (tc *TypeChecker) inferType(term ast.Term) Type {
    switch t := term.(type) {
    case *ast.Number:
        return TypeNumber
    case *ast.String:
        return TypeString
    case *ast.Boolean:
        return TypeBoolean
    case *ast.Array:
        elemType := tc.inferArrayElementType(t)
        return &ArrayType{Element: elemType}
    case *ast.Object:
        keyType, valType := tc.inferObjectTypes(t)
        return &ObjectType{Key: keyType, Value: valType}
    case *ast.Var:
        return tc.env.Lookup(t.Value)
    case *ast.Ref:
        return tc.inferRefType(t)
    }
    return TypeAny
}
```

### 4.3 å®‰å…¨æ€§æ£€æŸ¥

**å®‰å…¨æ€§åˆ†æå™¨**ï¼š

```go
type SafetyChecker struct {
    errors []error
}

func (sc *SafetyChecker) Check(rule *ast.Rule) error {
    // æ”¶é›†æ‰€æœ‰å˜é‡
    vars := collectVars(rule)
    
    // æ£€æŸ¥å¦å®šä¸­çš„å˜é‡
    sc.checkNegation(rule, vars)
    
    // æ£€æŸ¥æ¨å¯¼ä¸­çš„å˜é‡
    sc.checkComprehensions(rule, vars)
    
    return sc.wrapErrors()
}

func (sc *SafetyChecker) checkNegation(rule *ast.Rule, safeVars map[string]bool) {
    for _, expr := range rule.Body {
        if not, ok := expr.(*ast.NotExpr); ok {
            // å¦å®šä¸­çš„æ‰€æœ‰å˜é‡å¿…é¡»åœ¨å¦å®šå‰å·²ç»‘å®š
            notVars := collectVars(not.Expr)
            for v := range notVars {
                if !safeVars[v] {
                    sc.errors = append(sc.errors,
                        fmt.Errorf("å¦å®šä¸­çš„æœªç»‘å®šå˜é‡: %s", v))
                }
            }
        }
    }
}
```

---

## 5. ä¸­é—´ä»£ç ç”Ÿæˆ

### 5.1 IRç”Ÿæˆç­–ç•¥

**è§„åˆ™åˆ°IRè½¬æ¢**ï¼š

```go
type IRBuilder struct {
    nextBlockID  int
    nextRegister int
}

func (ib *IRBuilder) BuildRule(rule *ast.Rule) *IR {
    ir := &IR{
        Name:   rule.Head.Name,
        Blocks: make([]*Block, 0),
    }
    
    // åˆ›å»ºå…¥å£å—
    entry := ib.newBlock("entry")
    ir.Blocks = append(ir.Blocks, entry)
    
    // ç¼–è¯‘Body
    for _, expr := range rule.Body {
        ib.compileExpr(expr, entry)
    }
    
    // ç¼–è¯‘Head
    result := ib.compileHead(rule.Head, entry)
    
    // è¿”å›ç»“æœ
    entry.addInstr(&Return{Value: result})
    
    return ir
}

func (ib *IRBuilder) compileExpr(expr ast.Expr, block *Block) Register {
    switch e := expr.(type) {
    case *ast.InfixExpr:
        return ib.compileInfix(e, block)
    case *ast.CallExpr:
        return ib.compileCall(e, block)
    case *ast.RefExpr:
        return ib.compileRef(e, block)
    }
    return 0
}

func (ib *IRBuilder) compileInfix(expr *ast.InfixExpr, block *Block) Register {
    left := ib.compileExpr(expr.Left, block)
    right := ib.compileExpr(expr.Right, block)
    
    result := ib.newRegister()
    
    switch expr.Operator {
    case "+":
        block.addInstr(&Add{Dst: result, Src1: left, Src2: right})
    case "==":
        block.addInstr(&Eq{Dst: result, Src1: left, Src2: right})
    // ... å…¶ä»–è¿ç®—ç¬¦
    }
    
    return result
}
```

### 5.2 æ§åˆ¶æµå›¾æ„å»º

**CFGï¼ˆControl Flow Graphï¼‰**ï¼š

```go
type CFG struct {
    Blocks []*Block
    Entry  *Block
    Exit   *Block
}

type Block struct {
    ID           int
    Label        string
    Instructions []Instruction
    Successors   []*Block
    Predecessors []*Block
}

func BuildCFG(ir *IR) *CFG {
    cfg := &CFG{
        Blocks: ir.Blocks,
        Entry:  ir.Blocks[0],
    }
    
    // æ„å»ºè¾¹
    for _, block := range ir.Blocks {
        lastInstr := block.Instructions[len(block.Instructions)-1]
        
        switch instr := lastInstr.(type) {
        case *Jump:
            target := findBlock(ir.Blocks, instr.Label)
            block.Successors = append(block.Successors, target)
            target.Predecessors = append(target.Predecessors, block)
            
        case *Branch:
            trueTarget := findBlock(ir.Blocks, instr.TrueLabel)
            falseTarget := findBlock(ir.Blocks, instr.FalseLabel)
            
            block.Successors = append(block.Successors, trueTarget, falseTarget)
            trueTarget.Predecessors = append(trueTarget.Predecessors, block)
            falseTarget.Predecessors = append(falseTarget.Predecessors, block)
        }
    }
    
    return cfg
}
```

### 5.3 SSAè½¬æ¢

**SSAï¼ˆStatic Single Assignmentï¼‰å½¢å¼**ï¼š

```text
// åŸå§‹IR
x = 1
x = x + 2

// SSAå½¢å¼
x_1 = 1
x_2 = x_1 + 2
```

**Î¦å‡½æ•°æ’å…¥**ï¼š

```go
func ConvertToSSA(cfg *CFG) {
    // 1. æ’å…¥Î¦å‡½æ•°
    insertPhiFunctions(cfg)
    
    // 2. å˜é‡é‡å‘½å
    renameVariables(cfg)
}

func insertPhiFunctions(cfg *CFG) {
    for _, block := range cfg.Blocks {
        if len(block.Predecessors) > 1 {
            // ä¸ºæ‰€æœ‰å˜é‡æ’å…¥Î¦å‡½æ•°
            vars := collectDefinedVars(block)
            for _, v := range vars {
                phi := &Phi{
                    Dst:     newSSAVar(v),
                    Sources: make([]Register, len(block.Predecessors)),
                }
                block.prependInstr(phi)
            }
        }
    }
}
```

---

## 6. ä¼˜åŒ–

### 6.1 å±€éƒ¨ä¼˜åŒ–

**å¸¸é‡æŠ˜å **ï¼š

```go
func ConstantFolding(block *Block) {
    for i, instr := range block.Instructions {
        switch op := instr.(type) {
        case *Add:
            if isConst(op.Src1) && isConst(op.Src2) {
                val := getConstValue(op.Src1) + getConstValue(op.Src2)
                block.Instructions[i] = &LoadConst{Dst: op.Dst, Value: val}
            }
        case *Mul:
            if isConst(op.Src1) && isConst(op.Src2) {
                val := getConstValue(op.Src1) * getConstValue(op.Src2)
                block.Instructions[i] = &LoadConst{Dst: op.Dst, Value: val}
            }
        }
    }
}
```

**å¼ºåº¦å‰Šå‡**ï¼š

```go
// x * 2  â†’  x + x
// x * 4  â†’  x << 2
func StrengthReduction(block *Block) {
    for i, instr := range block.Instructions {
        if mul, ok := instr.(*Mul); ok {
            if isConst(mul.Src2) {
                val := getConstValue(mul.Src2)
                if isPowerOfTwo(val) {
                    // æ›¿æ¢ä¸ºç§»ä½
                    shift := log2(val)
                    block.Instructions[i] = &Shl{
                        Dst:  mul.Dst,
                        Src:  mul.Src1,
                        Amt:  shift,
                    }
                }
            }
        }
    }
}
```

### 6.2 å…¨å±€ä¼˜åŒ–

**æ­»ä»£ç æ¶ˆé™¤**ï¼š

```go
func DeadCodeElimination(cfg *CFG) {
    // 1. æ ‡è®°æ´»è·ƒæŒ‡ä»¤
    alive := make(map[Instruction]bool)
    worklist := []Instruction{}
    
    // åˆå§‹åŒ–ï¼šè¿”å›è¯­å¥å’Œæœ‰å‰¯ä½œç”¨çš„æŒ‡ä»¤
    for _, block := range cfg.Blocks {
        for _, instr := range block.Instructions {
            if isCritical(instr) {
                alive[instr] = true
                worklist = append(worklist, instr)
            }
        }
    }
    
    // 2. åå‘ä¼ æ’­
    for len(worklist) > 0 {
        instr := worklist[0]
        worklist = worklist[1:]
        
        for _, operand := range instr.Operands() {
            defInstr := findDefinition(operand)
            if !alive[defInstr] {
                alive[defInstr] = true
                worklist = append(worklist, defInstr)
            }
        }
    }
    
    // 3. åˆ é™¤æ­»ä»£ç 
    for _, block := range cfg.Blocks {
        newInstrs := []Instruction{}
        for _, instr := range block.Instructions {
            if alive[instr] {
                newInstrs = append(newInstrs, instr)
            }
        }
        block.Instructions = newInstrs
    }
}
```

### 6.3 æ•°æ®æµåˆ†æ

**åˆ°è¾¾å®šä¹‰åˆ†æ**ï¼š

```go
type ReachingDefs struct {
    Gen  map[*Block]Set  // å—ç”Ÿæˆçš„å®šä¹‰
    Kill map[*Block]Set  // å—æ€æ­»çš„å®šä¹‰
    In   map[*Block]Set  // å—å…¥å£çš„å®šä¹‰
    Out  map[*Block]Set  // å—å‡ºå£çš„å®šä¹‰
}

func ComputeReachingDefs(cfg *CFG) *ReachingDefs {
    rd := &ReachingDefs{
        Gen:  make(map[*Block]Set),
        Kill: make(map[*Block]Set),
        In:   make(map[*Block]Set),
        Out:  make(map[*Block]Set),
    }
    
    // è®¡ç®—Genå’ŒKill
    for _, block := range cfg.Blocks {
        rd.Gen[block] = computeGen(block)
        rd.Kill[block] = computeKill(block)
    }
    
    // è¿­ä»£æ±‚è§£
    changed := true
    for changed {
        changed = false
        for _, block := range cfg.Blocks {
            // In[B] = âˆª Out[P] for P in predecessors(B)
            newIn := NewSet()
            for _, pred := range block.Predecessors {
                newIn = newIn.Union(rd.Out[pred])
            }
            
            // Out[B] = Gen[B] âˆª (In[B] - Kill[B])
            newOut := rd.Gen[block].Union(
                newIn.Difference(rd.Kill[block]),
            )
            
            if !newIn.Equals(rd.In[block]) || !newOut.Equals(rd.Out[block]) {
                changed = true
                rd.In[block] = newIn
                rd.Out[block] = newOut
            }
        }
    }
    
    return rd
}
```

---

## 7. ä»£ç ç”Ÿæˆ

### 7.1 å­—èŠ‚ç ç”Ÿæˆ

**å­—èŠ‚ç å®šä¹‰**ï¼š

```go
type Opcode byte

const (
    OP_LOAD_CONST Opcode = iota
    OP_LOAD_VAR
    OP_STORE_VAR
    OP_ADD
    OP_SUB
    OP_MUL
    OP_EQ
    OP_JUMP
    OP_JUMP_IF_FALSE
    OP_CALL
    OP_RETURN
)

type BytecodeGenerator struct {
    code []byte
}

func (bg *BytecodeGenerator) Generate(ir *IR) []byte {
    for _, block := range ir.Blocks {
        for _, instr := range block.Instructions {
            bg.emitInstruction(instr)
        }
    }
    return bg.code
}

func (bg *BytecodeGenerator) emitInstruction(instr Instruction) {
    switch i := instr.(type) {
    case *LoadConst:
        bg.emit(OP_LOAD_CONST)
        bg.emitInt(i.Dst)
        bg.emitValue(i.Value)
    case *Add:
        bg.emit(OP_ADD)
        bg.emitInt(i.Dst)
        bg.emitInt(i.Src1)
        bg.emitInt(i.Src2)
    case *Return:
        bg.emit(OP_RETURN)
        bg.emitInt(i.Value)
    }
}
```

### 7.2 WASMç”Ÿæˆ

**WASMä»£ç ç”Ÿæˆå™¨**ï¼š

```go
func GenerateWASM(ir *IR) []byte {
    module := &wasm.Module{
        Types: []wasm.FunctionType{
            {
                Params:  []wasm.ValueType{wasm.I32},
                Results: []wasm.ValueType{wasm.I32},
            },
        },
        Functions: []wasm.Function{},
        Exports: []wasm.Export{
            {
                Name: "eval",
                Kind: wasm.ExternalFunction,
                Index: 0,
            },
        },
    }
    
    // ç”Ÿæˆå‡½æ•°ä½“
    funcBody := generateWASMFunction(ir)
    module.Functions = append(module.Functions, funcBody)
    
    // ç¼–ç ä¸ºå­—èŠ‚
    return wasm.Encode(module)
}

func generateWASMFunction(ir *IR) wasm.Function {
    code := []byte{}
    
    for _, block := range ir.Blocks {
        for _, instr := range block.Instructions {
            switch i := instr.(type) {
            case *LoadConst:
                code = append(code, wasm.I32Const)
                code = appendLEB128(code, i.Value)
            case *Add:
                code = append(code, wasm.LocalGet, byte(i.Src1))
                code = append(code, wasm.LocalGet, byte(i.Src2))
                code = append(code, wasm.I32Add)
                code = append(code, wasm.LocalSet, byte(i.Dst))
            case *Return:
                code = append(code, wasm.LocalGet, byte(i.Value))
                code = append(code, wasm.Return)
            }
        }
    }
    
    return wasm.Function{Code: code}
}
```

### 7.3 åŸç”Ÿä»£ç ç”Ÿæˆ

**JITç¼–è¯‘ï¼ˆæ¦‚å¿µï¼‰**ï¼š

```go
// ä½¿ç”¨ LLVM æˆ– cranelift ç”ŸæˆåŸç”Ÿä»£ç 
func CompileToNative(ir *IR) (*NativeCode, error) {
    // 1. IR â†’ LLVM IR
    llvmModule := convertToLLVM(ir)
    
    // 2. LLVMä¼˜åŒ–
    runLLVMOptimizations(llvmModule)
    
    // 3. ç”Ÿæˆæœºå™¨ç 
    machineCode := llvmModule.Compile()
    
    // 4. JITæ‰§è¡Œ
    return &NativeCode{
        Code:   machineCode,
        Entry:  machineCode.GetFunction("eval"),
    }, nil
}
```

---

## 8. é”™è¯¯å¤„ç†ä¸æ¢å¤

### 8.1 é”™è¯¯åˆ†ç±»

**é”™è¯¯ç±»å‹**ï¼š

```go
type CompileError interface {
    error
    Location() *Location
    Level() ErrorLevel
}

type ErrorLevel int

const (
    ERROR   ErrorLevel = iota  // è‡´å‘½é”™è¯¯
    WARNING                    // è­¦å‘Š
    INFO                       // ä¿¡æ¯
)

type SyntaxError struct {
    Loc     *Location
    Message string
}

type TypeError struct {
    Loc      *Location
    Expected Type
    Got      Type
}

type SafetyError struct {
    Loc  *Location
    Var  string
    Kind SafetyViolation
}
```

### 8.2 é”™è¯¯æ¢å¤ç­–ç•¥

**Panicæ¨¡å¼æ¢å¤**ï¼š

```go
func (p *Parser) synchronize() {
    p.panicMode = false
    
    for !p.curTokenIs(EOF) {
        if p.peekTokenIs(SEMICOLON) {
            p.nextToken()
            return
        }
        
        switch p.curToken.Type {
        case PACKAGE, IMPORT, DEFAULT:
            return
        }
        
        p.nextToken()
    }
}

func (p *Parser) parseRule() *ast.Rule {
    defer func() {
        if r := recover(); r != nil {
            p.errors = append(p.errors, r.(error))
            p.synchronize()
        }
    }()
    
    // è§£æé€»è¾‘...
}
```

### 8.3 è¯Šæ–­ä¿¡æ¯

**é”™è¯¯æŠ¥å‘Šæ ¼å¼**ï¼š

```go
func FormatError(err CompileError, source string) string {
    loc := err.Location()
    lines := strings.Split(source, "\n")
    
    // æ„å»ºé”™è¯¯ä¿¡æ¯
    var buf bytes.Buffer
    
    // æ–‡ä»¶ä½ç½®
    fmt.Fprintf(&buf, "%s:%d:%d: %s\n",
        loc.File, loc.Row, loc.Col, err.Error())
    
    // æºä»£ç è¡Œ
    if loc.Row > 0 && loc.Row <= len(lines) {
        line := lines[loc.Row-1]
        fmt.Fprintf(&buf, "%5d | %s\n", loc.Row, line)
        
        // é”™è¯¯æŒ‡ç¤ºç¬¦
        fmt.Fprintf(&buf, "      | %s^\n",
            strings.Repeat(" ", loc.Col-1))
    }
    
    return buf.String()
}
```

---

## 9. ç¼–è¯‘å™¨ä¼˜åŒ–æŠ€æœ¯

### 9.1 éƒ¨åˆ†æ±‚å€¼

**éƒ¨åˆ†æ±‚å€¼ä¼˜åŒ–**ï¼š

```go
func PartialEval(module *ast.Module, knownData map[string]interface{}) *ast.Module {
    optimizer := &PartialEvaluator{
        data: knownData,
    }
    
    optimized := &ast.Module{
        Package: module.Package,
        Imports: module.Imports,
    }
    
    for _, rule := range module.Rules {
        optRule := optimizer.evalRule(rule)
        if optRule != nil {
            optimized.Rules = append(optimized.Rules, optRule)
        }
    }
    
    return optimized
}

func (pe *PartialEvaluator) evalRule(rule *ast.Rule) *ast.Rule {
    newBody := []ast.Expr{}
    
    for _, expr := range rule.Body {
        // å°è¯•æ±‚å€¼è¡¨è¾¾å¼
        if result, ok := pe.tryEval(expr); ok {
            if !result {
                // è¡¨è¾¾å¼ä¸ºfalseï¼Œæ•´ä¸ªè§„åˆ™å¤±è´¥
                return nil
            }
            // è¡¨è¾¾å¼ä¸ºtrueï¼Œå¯ä»¥åˆ é™¤
            continue
        }
        newBody = append(newBody, expr)
    }
    
    return &ast.Rule{
        Head: rule.Head,
        Body: newBody,
    }
}
```

### 9.2 ç´¢å¼•æ„å»º

**è‡ªåŠ¨ç´¢å¼•ç”Ÿæˆ**ï¼š

```go
type IndexBuilder struct {
    indexes map[string]*Index
}

func (ib *IndexBuilder) BuildIndexes(module *ast.Module) {
    // åˆ†æè®¿é—®æ¨¡å¼
    patterns := ib.analyzeAccessPatterns(module)
    
    // ä¸ºé¢‘ç¹è®¿é—®çš„è·¯å¾„æ„å»ºç´¢å¼•
    for _, pattern := range patterns {
        if pattern.Frequency > THRESHOLD {
            index := ib.createIndex(pattern)
            ib.indexes[pattern.Path] = index
        }
    }
}

type Index struct {
    Path     string
    KeyType  Type
    ValueMap map[interface{}]interface{}
}

func (ib *IndexBuilder) createIndex(pattern AccessPattern) *Index {
    index := &Index{
        Path:     pattern.Path,
        KeyType:  pattern.KeyType,
        ValueMap: make(map[interface{}]interface{}),
    }
    
    // æ„å»ºç´¢å¼•æ˜ å°„
    for _, item := range pattern.Data {
        key := extractKey(item, pattern.KeyPath)
        index.ValueMap[key] = item
    }
    
    return index
}
```

### 9.3 è§„åˆ™é‡å†™

**è§„åˆ™ç®€åŒ–**ï¼š

```go
// åˆå¹¶ç›¸åŒæ¡ä»¶çš„è§„åˆ™
func MergeRules(rules []*ast.Rule) []*ast.Rule {
    groups := groupByConditions(rules)
    merged := []*ast.Rule{}
    
    for _, group := range groups {
        if len(group) > 1 {
            // åˆå¹¶ä¸ºå•ä¸ªè§„åˆ™
            merged = append(merged, mergeGroup(group))
        } else {
            merged = append(merged, group[0])
        }
    }
    
    return merged
}

// ç¤ºä¾‹ï¼š
// rule1 if { x > 10; y == 5 }
// rule1 if { x > 10; y == 6 }
// â†’
// rule1 if { x > 10; y in {5, 6} }
```

---

## 10. å®è·µæ¡ˆä¾‹

### 10.1 ç¼–è¯‘ç®€å•ç­–ç•¥

**è¾“å…¥ç­–ç•¥**ï¼š

```rego
package authz

allow if {
    input.user == "admin"
}
```

**ç¼–è¯‘æ­¥éª¤**ï¼š

```text
1. Lexerè¾“å‡º:
   PACKAGE, IDENT("authz"), IDENT("allow"), IF, ...

2. Parserè¾“å‡ºAST:
   Module(
     Package("authz"),
     Rule(
       Head("allow"),
       Body([
         Expr(Eq(Ref("input.user"), String("admin")))
       ])
     )
   )

3. IRç”Ÿæˆ:
   function authz.allow:
     %1 = load input
     %2 = get %1, "user"
     %3 = eq %2, "admin"
     return %3

4. ä¼˜åŒ–åIR:
   (æ— å˜åŒ–)

5. å­—èŠ‚ç :
   LOAD_VAR input
   GET_FIELD "user"
   LOAD_CONST "admin"
   EQ
   RETURN
```

### 10.2 ç¼–è¯‘å¤æ‚æ¨å¯¼

**è¾“å…¥ç­–ç•¥**ï¼š

```rego
admins := [u | 
    some u in data.users
    u.role == "admin"
]
```

**IRç”Ÿæˆ**ï¼š

```text
function authz.admins:
  %result = make_array []
  %users = load data.users
  %iter = scan %users
  
loop:
  %u = next %iter
  branch_exhausted %iter, done
  
  %role = get %u, "role"
  %cond = eq %role, "admin"
  branch_not %cond, loop
  
  append %result, %u
  jump loop
  
done:
  return %result
```

### 10.3 ç¼–è¯‘é€’å½’è§„åˆ™

**è¾“å…¥ç­–ç•¥**ï¼š

```rego
reachable[y] if {
    edge[input.start][y]
}

reachable[z] if {
    reachable[y]
    edge[y][z]
}
```

**ç¼–è¯‘ç­–ç•¥**ï¼š

```text
1. æ£€æµ‹é€’å½’
2. ç”Ÿæˆfixpointè¿­ä»£ä»£ç 
3. ä½¿ç”¨å·¥ä½œè¡¨ç®—æ³•

ä¼ªä»£ç :
worklist = {input.start}
result = set()

while worklist not empty:
    x = worklist.pop()
    if x in result:
        continue
    result.add(x)
    
    for y in edge[x]:
        worklist.add(y)

return result
```

---

## é™„å½•Aï¼šç¼–è¯‘å™¨å®ç°ä»£ç 

**å®Œæ•´ç¼–è¯‘å™¨æ¡†æ¶**ï¼š

```go
package compiler

type Compiler struct {
    lexer      *Lexer
    parser     *Parser
    analyzer   *SemanticAnalyzer
    irBuilder  *IRBuilder
    optimizer  *Optimizer
    codegen    *CodeGenerator
}

func NewCompiler() *Compiler {
    return &Compiler{
        analyzer:  NewSemanticAnalyzer(),
        irBuilder: NewIRBuilder(),
        optimizer: NewOptimizer(),
        codegen:   NewCodeGenerator(),
    }
}

func (c *Compiler) Compile(source string) (*CompiledModule, error) {
    // 1. è¯æ³•å’Œè¯­æ³•åˆ†æ
    c.lexer = NewLexer(source)
    c.parser = NewParser(c.lexer)
    ast, err := c.parser.Parse()
    if err != nil {
        return nil, err
    }
    
    // 2. è¯­ä¹‰åˆ†æ
    if err := c.analyzer.Analyze(ast); err != nil {
        return nil, err
    }
    
    // 3. IRç”Ÿæˆ
    ir := c.irBuilder.Build(ast)
    
    // 4. ä¼˜åŒ–
    optimizedIR := c.optimizer.Optimize(ir)
    
    // 5. ä»£ç ç”Ÿæˆ
    code := c.codegen.Generate(optimizedIR)
    
    return &CompiledModule{
        AST:  ast,
        IR:   optimizedIR,
        Code: code,
    }, nil
}
```

---

## é™„å½•Bï¼šä¼˜åŒ–Passæ¸…å•

**æ¨èä¼˜åŒ–Passé¡ºåº**ï¼š

```text
1. å¸¸é‡ä¼ æ’­ (Constant Propagation)
2. å¸¸é‡æŠ˜å  (Constant Folding)
3. æ­»ä»£ç æ¶ˆé™¤ (Dead Code Elimination)
4. å…¬å…±å­è¡¨è¾¾å¼æ¶ˆé™¤ (Common Subexpression Elimination)
5. å¤å†™ä¼ æ’­ (Copy Propagation)
6. å¼ºåº¦å‰Šå‡ (Strength Reduction)
7. å¾ªç¯ä¸å˜ä»£ç å¤–æ (Loop Invariant Code Motion)
8. å‡½æ•°å†…è” (Inlining)
9. å°¾è°ƒç”¨ä¼˜åŒ– (Tail Call Optimization)
10. éƒ¨åˆ†æ±‚å€¼ (Partial Evaluation)
```

---

**ç›¸å…³æ–‡æ¡£**ï¼š

- [è¯æ³•åˆ†æä¸è¯­æ³•è§£æ](./03.1-è¯æ³•åˆ†æä¸è¯­æ³•è§£æ.md)
- [ASTä¸IR](./03.2-ASTä¸IR.md)
- [Top-Downæ±‚å€¼å™¨](./03.4-Top-Downæ±‚å€¼å™¨.md)

**å‚è€ƒèµ„æº**ï¼š

- Dragon Book: "Compilers: Principles, Techniques, and Tools"
- LLVM Documentation: <https://llvm.org/docs/>
- OPA Compiler Source: <https://github.com/open-policy-agent/opa/tree/main/ast>
