# SLD-Resolution详解

> **文档类型**: 算法深度分析  
> **核心算法**: SLD-Resolution (Selective Linear Definite Resolution)  
> **适用读者**: 算法研究者、逻辑编程专家、OPA核心开发者  
> **先修知识**: [命题逻辑与一阶逻辑](../06-形式化证明/06.3-命题逻辑与一阶逻辑基础.md)、[求值算法正确性](../06-形式化证明/06.4-求值算法正确性证明.md)  
> **最后更新**: 2025年10月23日  
> **文档状态**: ✅ Phase 3.1 - 算法分析  
> **理论基础**: Datalog, Prolog, Horn子句

---

## 🎯 文档目标

本文档深入分析OPA使用的**SLD-Resolution**算法，这是逻辑编程的核心求解机制。

**核心内容**:

- SLD-Resolution的理论基础
- 算法的详细步骤和数据结构
- 选择函数与搜索策略
- 正确性与完备性分析
- OPA中的具体实现

**学习价值**:

- 理解逻辑编程的执行模型
- 掌握回溯搜索算法
- 优化策略求值性能
- 实现自定义求值器

---

## 目录

- [SLD-Resolution详解](#sld-resolution详解)
  - [🎯 文档目标](#-文档目标)
  - [目录](#目录)
  - [1. 理论基础](#1-理论基础)
    - [1.1 Horn子句](#11-horn子句)
    - [1.2 Resolution原理](#12-resolution原理)
    - [1.3 SLD的特殊性](#13-sld的特殊性)
  - [2. 算法定义](#2-算法定义)
    - [2.1 基本概念](#21-基本概念)
    - [2.2 SLD推导](#22-sld推导)
    - [2.3 SLD树](#23-sld树)
  - [3. 算法过程](#3-算法过程)
    - [3.1 初始化](#31-初始化)
    - [3.2 选择目标](#32-选择目标)
    - [3.3 规则匹配](#33-规则匹配)
    - [3.4 统一与替换](#34-统一与替换)
    - [3.5 生成新目标](#35-生成新目标)
  - [4. 选择函数](#4-选择函数)
    - [4.1 Prolog的左优先策略](#41-prolog的左优先策略)
    - [4.2 OPA的选择策略](#42-opa的选择策略)
    - [4.3 智能选择优化](#43-智能选择优化)
  - [5. 搜索策略](#5-搜索策略)
    - [5.1 深度优先搜索](#51-深度优先搜索)
    - [5.2 广度优先搜索](#52-广度优先搜索)
    - [5.3 迭代加深](#53-迭代加深)
  - [6. 回溯机制](#6-回溯机制)
    - [6.1 选择点](#61-选择点)
    - [6.2 回溯栈](#62-回溯栈)
    - [6.3 剪枝优化](#63-剪枝优化)
  - [7. 正确性分析](#7-正确性分析)
    - [7.1 可靠性定理](#71-可靠性定理)
    - [7.2 完备性定理](#72-完备性定理)
    - [7.3 终止性分析](#73-终止性分析)
  - [8. 复杂度分析](#8-复杂度分析)
    - [8.1 时间复杂度](#81-时间复杂度)
    - [8.2 空间复杂度](#82-空间复杂度)
    - [8.3 最坏情况](#83-最坏情况)
  - [9. OPA中的实现](#9-opa中的实现)
    - [9.1 数据结构](#91-数据结构)
    - [9.2 求值循环](#92-求值循环)
    - [9.3 优化技术](#93-优化技术)
  - [10. 实战示例](#10-实战示例)
    - [10.1 简单查询](#101-简单查询)
    - [10.2 递归查询](#102-递归查询)
    - [10.3 否定查询](#103-否定查询)
  - [附录](#附录)
    - [A. 形式化定义](#a-形式化定义)
    - [B. 证明细节](#b-证明细节)
    - [C. 性能对比](#c-性能对比)

---

## 1. 理论基础

### 1.1 Horn子句

**定义**:

Horn子句是一阶逻辑中的特殊子句形式：

```text
H ← B₁, B₂, ..., Bₙ
```

其中：

- `H`: 头部（Head），一个原子
- `Bᵢ`: 体部（Body），原子的合取

**三种形式**:

1. **确定子句** (Definite Clause): `H ← B₁, ..., Bₙ` (n ≥ 0)
2. **目标子句** (Goal Clause): `← B₁, ..., Bₙ` (无头部)
3. **单元子句** (Unit Clause): `H ←` (无体部，事实)

**示例**:

```prolog
% 事实（单元子句）
parent(tom, bob).
parent(bob, ann).

% 规则（确定子句）
grandparent(X, Z) :- parent(X, Y), parent(Y, Z).

% 查询（目标子句）
?- grandparent(tom, ann).
```

### 1.2 Resolution原理

**Resolution规则**:

给定两个子句：

- `C₁ = H ∨ L₁ ∨ ... ∨ Lₘ`
- `C₂ = ¬H ∨ K₁ ∨ ... ∨ Kₙ`

可以推导出：

- `R = (L₁ ∨ ... ∨ Lₘ ∨ K₁ ∨ ... ∨ Kₙ)σ`

其中`σ`是使`H`和`¬H`统一的最一般统一子（MGU）。

**Horn子句的Resolution**:

对于Horn子句，Resolution有特殊性质：

```text
C₁: H ← B₁, ..., Bₘ
C₂: ← G₁, ..., H, ..., Gₙ  (H在某个位置)
───────────────────────────
R:  ← G₁, ..., B₁, ..., Bₘ, ..., Gₙ
```

### 1.3 SLD的特殊性

**SLD = Selective Linear Definite Resolution**:

- **Selective**: 每次只选择目标中的一个原子
- **Linear**: 始终使用一个目标子句
- **Definite**: 只适用于Horn子句

**特点**:

1. ✅ **简单**: 算法直观，易于实现
2. ✅ **高效**: 避免了一般Resolution的搜索空间爆炸
3. ✅ **完备**: 对于Horn子句，保证找到所有答案
4. ⚠️ **限制**: 只适用于Horn子句

---

## 2. 算法定义

### 2.1 基本概念

**程序（Program）**:

```text
P = {C₁, C₂, ..., Cₙ}
```

其中每个`Cᵢ`是确定子句。

**目标（Goal）**:

```text
G = ← A₁, A₂, ..., Aₘ
```

**答案替换（Answer Substitution）**:

如果从`G`推导出空子句，则累积的替换`θ`是答案。

### 2.2 SLD推导

**定义**:

给定程序`P`和目标`G = ← A₁, ..., Aᵢ, ..., Aₘ`：

1. **选择**目标中的原子`Aᵢ`
2. **匹配**程序中的子句`C = H ← B₁, ..., Bₙ`
3. **统一** `Aᵢ`和`H`，得到MGU `θ`
4. **替换**产生新目标: `G' = (← A₁, ..., Aᵢ₋₁, B₁, ..., Bₙ, Aᵢ₊₁, ..., Aₘ)θ`

**推导序列**:

```text
G₀ ⟹ᶜ¹'ᶿ¹ G₁ ⟹ᶜ²'ᶿ² G₂ ⟹ ... ⟹ᶜⁿ'ᶿⁿ Gₙ
```

其中：

- `Gᵢ`是目标
- `Cⁱ`是使用的子句
- `θⁱ`是统一替换

**成功推导**:

如果`Gₙ = □`（空子句），则推导成功，答案是`θ = θ₁θ₂...θₙ`。

### 2.3 SLD树

**定义**:

SLD树是所有可能SLD推导的搜索空间：

```text
                 G₀
               /  |  \
             /    |    \
           G₁    G₁'   G₁''
          / \     |     ...
        /    \    |
      G₂     G₂' G₂''
      |       |    ...
     □       ...
  (成功)
```

**节点**:

- 根节点：初始目标
- 内部节点：中间目标
- 叶节点：空子句（成功）或失败

**边**:

- 标记为`(C, θ)`，表示使用子句`C`和替换`θ`

**完备性**:

如果答案存在，则在SLD树的某条分支上。

---

## 3. 算法过程

### 3.1 初始化

```text
输入: 
  - 程序 P = {C₁, ..., Cₙ}
  - 查询 Q = ?- A₁, ..., Aₘ

初始化:
  - 当前目标: G = ← A₁, ..., Aₘ
  - 答案替换: θ = ∅ (空)
  - 回溯栈: Stack = []
```

### 3.2 选择目标

**选择函数** `select(G)`:

从目标`G = ← A₁, ..., Aₘ`中选择一个原子`Aᵢ`。

**常见策略**:

1. **左优先**: 总是选择最左边的原子（Prolog）
2. **右优先**: 总是选择最右边的原子
3. **智能选择**: 根据启发式选择

**示例**:

```text
G = ← parent(X, Y), parent(Y, ann)
select(G) = parent(X, Y)  // 左优先
```

### 3.3 规则匹配

**匹配过程**:

给定选中的原子`A`，查找程序中所有可匹配的子句：

```text
matches(A, P) = { C ∈ P | head(C)和A可统一 }
```

**示例**:

```text
A = parent(tom, Y)

P中的子句:
  C₁: parent(tom, bob) ←
  C₂: parent(bob, ann) ←
  C₃: parent(X, Z) ← father(X, Z)

matches(A, P) = {C₁, C₃}
```

### 3.4 统一与替换

**统一算法** (详见[Robinson统一算法](11.2-Robinson统一算法.md)):

```text
unify(A, head(C)) = θ (MGU) or fail
```

**应用替换**:

```text
G' = (G - {A} ∪ body(C))θ
```

**示例**:

```text
A = parent(tom, Y)
C = parent(tom, bob) ←

θ = unify(A, parent(tom, bob))
  = {Y/bob}

新目标: G' = Gθ (其中Y被替换为bob)
```

### 3.5 生成新目标

**替换规则**:

```text
G = ← A₁, ..., Aᵢ, ..., Aₘ
C = H ← B₁, ..., Bₙ
θ = unify(Aᵢ, H)
───────────────────────────────
G' = (← A₁, ..., Aᵢ₋₁, B₁, ..., Bₙ, Aᵢ₊₁, ..., Aₘ)θ
```

**特殊情况**:

1. **空体部**: `C = H ←`, 则`G' = (G - {Aᵢ})θ`
2. **空目标**: `G' = ←`, 推导成功
3. **无匹配**: 回溯

---

## 4. 选择函数

### 4.1 Prolog的左优先策略

**定义**:

```text
select(← A₁, ..., Aₘ) = A₁
```

总是选择最左边的原子。

**优点**:

- ✅ 简单确定
- ✅ 尾递归优化
- ✅ 易于理解和调试

**缺点**:

- ⚠️ 可能陷入无限循环
- ⚠️ 不是最优选择

**示例问题**:

```prolog
% 左递归规则
path(X, Y) :- edge(X, Y).
path(X, Y) :- path(X, Z), edge(Z, Y).

% 查询会无限循环
?- path(a, b).
```

### 4.2 OPA的选择策略

OPA使用**智能选择**策略：

**启发式规则**:

1. **优先Ground原子**: 完全确定的原子
2. **索引支持**: 有索引可用的原子
3. **估计基数**: 预期结果少的原子
4. **依赖顺序**: 满足变量依赖

**伪代码**:

```go
func selectBest(goals []Goal) Goal {
    var best Goal
    bestScore := -1
    
    for _, goal := range goals {
        score := 0
        
        if goal.IsGround() {
            score += 1000
        }
        
        if hasIndex(goal) {
            score += 500
        }
        
        score += (1000 - estimateCardinality(goal))
        
        if score > bestScore {
            bestScore = score
            best = goal
        }
    }
    
    return best
}
```

### 4.3 智能选择优化

**动态重排序**:

在求值过程中，根据已知绑定动态调整原子顺序。

**示例**:

```text
初始目标: ← expensive(X), cheap(X)

如果cheap(X)更高效:
重排序为: ← cheap(X), expensive(X)

求值cheap(X)后，X已绑定:
执行: expensive(known_value)  // 更快
```

---

## 5. 搜索策略

### 5.1 深度优先搜索

**Prolog和OPA默认策略**:

**算法**:

```text
DFS(G):
  if G = □:
    return success
  
  A = select(G)
  
  for each C in matches(A, P):
    θ = unify(A, head(C))
    if θ ≠ fail:
      G' = resolve(G, A, C, θ)
      if DFS(G') = success:
        return success
  
  return fail
```

**特点**:

- ✅ 空间复杂度低 O(深度)
- ✅ 找到第一个答案快
- ⚠️ 可能陷入无限深度
- ⚠️ 不保证找到最优解

### 5.2 广度优先搜索

**算法**:

```text
BFS(G₀):
  queue = [G₀]
  
  while queue not empty:
    G = queue.dequeue()
    
    if G = □:
      return success
    
    A = select(G)
    
    for each C in matches(A, P):
      θ = unify(A, head(C))
      if θ ≠ fail:
        G' = resolve(G, A, C, θ)
        queue.enqueue(G')
  
  return fail
```

**特点**:

- ✅ 完备性：总能找到最短答案
- ✅ 不会陷入无限深度
- ⚠️ 空间复杂度高 O(分支^深度)

### 5.3 迭代加深

**结合DFS和BFS优点**:

```text
IDDFS(G₀):
  for depth = 0 to ∞:
    if DFS_Limited(G₀, depth) = success:
      return success
  
  return fail
```

**特点**:

- ✅ 空间复杂度低（如DFS）
- ✅ 完备性（如BFS）
- ⚠️ 重复计算

---

## 6. 回溯机制

### 6.1 选择点

**定义**:

当一个原子有多个匹配子句时，创建选择点。

**选择点结构**:

```go
type ChoicePoint struct {
    Goal         Goal            // 当前目标
    Atom         Atom            // 选中的原子
    Clauses      []Clause        // 可选子句
    CurrentIndex int             // 当前尝试的索引
    Substitution Substitution    // 当前替换
}
```

### 6.2 回溯栈

**实现**:

```go
type BacktrackStack struct {
    stack []ChoicePoint
}

func (bs *BacktrackStack) Push(cp ChoicePoint) {
    bs.stack = append(bs.stack, cp)
}

func (bs *BacktrackStack) Pop() (ChoicePoint, bool) {
    if len(bs.stack) == 0 {
        return ChoicePoint{}, false
    }
    
    cp := bs.stack[len(bs.stack)-1]
    bs.stack = bs.stack[:len(bs.stack)-1]
    return cp, true
}

func (bs *BacktrackStack) Backtrack() bool {
    for {
        cp, ok := bs.Pop()
        if !ok {
            return false  // 没有更多选择点
        }
        
        cp.CurrentIndex++
        
        if cp.CurrentIndex < len(cp.Clauses) {
            // 还有未尝试的子句
            bs.Push(cp)
            return true
        }
        
        // 此选择点已穷尽，继续回溯
    }
}
```

### 6.3 剪枝优化

**Cut操作** (!):

Prolog的cut操作剪除当前选择点之后的所有分支。

**效果**:

```prolog
max(X, Y, X) :- X >= Y, !.
max(X, Y, Y).

% 查询: max(5, 3, Z)
% 第一个子句成功后，!阻止尝试第二个子句
```

**实现**:

```go
func Cut(stack *BacktrackStack, cutPoint int) {
    // 移除cutPoint之后的所有选择点
    stack.stack = stack.stack[:cutPoint]
}
```

---

## 7. 正确性分析

### 7.1 可靠性定理

**定理** (Soundness):

如果存在从目标`G`到空子句的SLD推导，且答案替换为`θ`，则`Gθ`在程序`P`的语义下为真。

**证明思路**:

1. 归纳SLD推导的步数
2. 每步Resolution保持逻辑蕴含关系
3. 空子句表示所有目标已满足

### 7.2 完备性定理

**定理** (Completeness):

如果`Gθ`在程序`P`的语义下为真，则存在从`G`到空子句的SLD推导，且答案替换`σ ≤ θ`（`σ`更一般）。

**注意**: 完备性依赖于选择函数的公平性。

### 7.3 终止性分析

**问题**: SLD-Resolution不保证终止。

**导致非终止的情况**:

1. **左递归**:

    ```prolog
    ancestor(X, Y) :- ancestor(X, Z), parent(Z, Y).
    ancestor(X, Y) :- parent(X, Y).
    ```

2. **无限数据结构**:

    ```prolog
    nat(0).
    nat(s(X)) :- nat(X).
    ```

**解决方案**:

- 循环检测
- 深度限制
- 重写规则（消除左递归）

---

## 8. 复杂度分析

### 8.1 时间复杂度

**最坏情况**: O(b^d)

其中：

- `b`: 分支因子（平均匹配子句数）
- `d`: 推导深度

**平均情况**: 依赖于程序结构和选择策略

### 8.2 空间复杂度

**DFS**: O(d)
**BFS**: O(b^d)

### 8.3 最坏情况

**指数爆炸**:

```prolog
p :- q, q.
q :- q.
q.

% 查询?- p. 会产生指数级选择
```

---

## 9. OPA中的实现

### 9.1 数据结构

```go
// Goal: 目标
type Goal struct {
    Literals []Literal
}

// Clause: 子句
type Clause struct {
    Head Literal
    Body []Literal
}

// Substitution: 替换
type Substitution map[Var]Term
```

### 9.2 求值循环

```go
func Eval(program []Clause, goal Goal) []Substitution {
    var results []Substitution
    stack := NewBacktrackStack()
    theta := NewSubstitution()
    
    for {
        if goal.IsEmpty() {
            // 成功
            results = append(results, theta)
            
            if !stack.Backtrack() {
                break
            }
            continue
        }
        
        // 选择原子
        atom := SelectBest(goal)
        
        // 匹配子句
        clauses := Match(atom, program)
        
        if len(clauses) == 0 {
            // 失败，回溯
            if !stack.Backtrack() {
                break
            }
            continue
        }
        
        // 创建选择点
        if len(clauses) > 1 {
            stack.Push(ChoicePoint{
                Goal:    goal,
                Atom:    atom,
                Clauses: clauses[1:],
                Theta:   theta,
            })
        }
        
        // 尝试第一个子句
        clause := clauses[0]
        mgu := Unify(atom, clause.Head)
        
        if mgu == nil {
            // 统一失败
            if !stack.Backtrack() {
                break
            }
            continue
        }
        
        // 更新目标和替换
        goal = Resolve(goal, atom, clause, mgu)
        theta = Compose(theta, mgu)
    }
    
    return results
}
```

### 9.3 优化技术

1. **索引**: 快速查找匹配子句
2. **缓存**: 记忆化已计算结果
3. **并行**: 多线程探索不同分支
4. **剪枝**: 提前排除不可能的分支

---

## 10. 实战示例

### 10.1 简单查询

**程序**:

```prolog
parent(tom, bob).
parent(bob, ann).
grandparent(X, Z) :- parent(X, Y), parent(Y, Z).
```

**查询**: `?- grandparent(tom, ann).`

**SLD推导**:

```text
G₀ = ← grandparent(tom, ann)

匹配: grandparent(X, Z) :- parent(X, Y), parent(Y, Z)
θ₁ = {X/tom, Z/ann}

G₁ = ← parent(tom, Y), parent(Y, ann)

匹配: parent(tom, bob)
θ₂ = {Y/bob}

G₂ = ← parent(bob, ann)

匹配: parent(bob, ann)
θ₃ = {}

G₃ = □ (成功!)

答案: θ = {X/tom, Y/bob, Z/ann}
```

### 10.2 递归查询

**程序**:

```prolog
ancestor(X, Y) :- parent(X, Y).
ancestor(X, Y) :- parent(X, Z), ancestor(Z, Y).

parent(a, b).
parent(b, c).
parent(c, d).
```

**查询**: `?- ancestor(a, d).`

**SLD树** (部分):

```text
← ancestor(a, d)
├─[使用规则1] ← parent(a, d) [失败]
└─[使用规则2] ← parent(a, Z₁), ancestor(Z₁, d)
   └─[Z₁=b] ← ancestor(b, d)
      ├─[使用规则1] ← parent(b, d) [失败]
      └─[使用规则2] ← parent(b, Z₂), ancestor(Z₂, d)
         └─[Z₂=c] ← ancestor(c, d)
            ├─[使用规则1] ← parent(c, d)
            │  └─[成功] □
            └─[使用规则2] ...
```

### 10.3 否定查询

**程序**:

```prolog
employee(alice).
employee(bob).
manager(alice).

non_manager(X) :- employee(X), \+ manager(X).
```

**查询**: `?- non_manager(bob).`

**NAF实现** (Negation as Failure):

```text
G₀ = ← non_manager(bob)

G₁ = ← employee(bob), \+ manager(bob)

G₂ = ← \+ manager(bob)  (employee(bob)成功)

尝试证明: ← manager(bob) [失败]

因此: \+ manager(bob) 成功

G₃ = □ (成功!)
```

---

## 附录

### A. 形式化定义

**SLD推导步骤**:

```text
⟨G, C, θ⟩ ∈ SLD-Step(P) ⟺
  ∃A ∈ G, ∃C ∈ P, ∃θ = mgu(A, head(C)) :
    G' = (G \ {A} ∪ body(C))θ
```

### B. 证明细节

详细的可靠性和完备性证明见[求值算法正确性证明](../06-形式化证明/06.4-求值算法正确性证明.md)。

### C. 性能对比

**不同策略的性能对比**:

| 策略 | 时间 | 空间 | 完备性 |
|------|------|------|--------|
| DFS  | O(b^d) | O(d) | ❌ |
| BFS  | O(b^d) | O(b^d) | ✅ |
| IDDFS | O(b^d) | O(d) | ✅ |
| A*   | O(b^d) | O(b^d) | ✅ |

---

**文档版本**: v1.0  
**最后更新**: 2025年10月23日  
**维护者**: OPA技术文档项目

**相关阅读**:

- [Robinson统一算法](11.2-Robinson统一算法.md) - 统一算法详解
- [求值算法正确性证明](../06-形式化证明/06.4-求值算法正确性证明.md) - 形式化证明
- [Top-Down求值器源码](../10-源码分析/10.5-Top-Down求值器源码.md) - 实现细节
