# 性能剖析实战

> **文档类型**: 理论实践桥梁  
> **核心主题**: OPA策略性能分析与优化实战  
> **适用读者**: 性能工程师、SRE、策略开发者  
> **先修知识**: [性能优化指南](../05-最佳实践/05.6-性能优化指南.md)、[查询优化算法](../11-算法深度/11.4-查询优化算法.md)  
> **最后更新**: 2025年10月23日  
> **文档状态**: ✅ Phase 4.2 - 理论实践  
> **实践价值**: 识别并解决OPA性能瓶颈

---

## 🎯 文档目标

本文档将**性能优化理论**应用于**实际策略剖析**，帮助工程师系统地分析和优化OPA性能。

**核心内容**:

- 性能剖析工具与方法
- 性能瓶颈识别与诊断
- 查询优化实战案例
- 内存与CPU优化技术
- 生产环境性能调优

**学习价值**:

- ⚡ 识别性能瓶颈
- 🔧 系统性优化策略
- 📊 建立性能基准
- 🎯 达成SLA目标

---

## 目录

- [性能剖析实战](#性能剖析实战)
  - [🎯 文档目标](#-文档目标)
  - [目录](#目录)
  - [1. 性能剖析基础](#1-性能剖析基础)
    - [1.1 性能指标](#11-性能指标)
    - [1.2 剖析方法论](#12-剖析方法论)
    - [1.3 优化流程](#13-优化流程)
  - [2. 剖析工具](#2-剖析工具)
    - [2.1 OPA内置工具](#21-opa内置工具)
    - [2.2 Go Profiling工具](#22-go-profiling工具)
    - [2.3 第三方工具](#23-第三方工具)
  - [3. 基准测试](#3-基准测试)
    - [3.1 建立Baseline](#31-建立baseline)
    - [3.2 压力测试](#32-压力测试)
    - [3.3 A/B测试](#33-ab测试)
  - [4. CPU剖析](#4-cpu剖析)
    - [4.1 CPU Profiling](#41-cpu-profiling)
    - [4.2 火焰图分析](#42-火焰图分析)
    - [4.3 热点函数优化](#43-热点函数优化)
  - [5. 内存剖析](#5-内存剖析)
    - [5.1 内存Profiling](#51-内存profiling)
    - [5.2 内存泄漏检测](#52-内存泄漏检测)
    - [5.3 GC优化](#53-gc优化)
  - [6. 查询优化](#6-查询优化)
    - [6.1 查询计划分析](#61-查询计划分析)
    - [6.2 索引优化](#62-索引优化)
    - [6.3 部分求值](#63-部分求值)
  - [7. 实战案例](#7-实战案例)
    - [7.1 慢查询优化](#71-慢查询优化)
    - [7.2 高并发场景](#72-高并发场景)
    - [7.3 大数据集优化](#73-大数据集优化)
  - [8. 监控与告警](#8-监控与告警)
    - [8.1 指标收集](#81-指标收集)
    - [8.2 监控仪表板](#82-监控仪表板)
    - [8.3 告警策略](#83-告警策略)
  - [9. 生产优化](#9-生产优化)
    - [9.1 配置调优](#91-配置调优)
    - [9.2 缓存策略](#92-缓存策略)
    - [9.3 扩展方案](#93-扩展方案)
  - [10. 最佳实践](#10-最佳实践)
    - [10.1 优化清单](#101-优化清单)
    - [10.2 反模式避免](#102-反模式避免)
    - [10.3 持续改进](#103-持续改进)
  - [附录](#附录)
    - [A. 工具参考](#a-工具参考)
    - [B. 性能检查清单](#b-性能检查清单)
    - [C. 优化案例库](#c-优化案例库)

---

## 1. 性能剖析基础

### 1.1 性能指标

**关键性能指标（KPI）**:

| 指标 | 目标值 | 测量方法 |
|------|--------|---------|
| **延迟 (Latency)** | P50 < 10ms, P99 < 50ms | 响应时间分布 |
| **吞吐量 (Throughput)** | > 1000 req/s | 每秒处理请求数 |
| **CPU使用率** | < 70% | CPU profiling |
| **内存使用** | < 2GB | 内存profiling |
| **GC暂停** | < 10ms | GC trace |
| **错误率** | < 0.1% | 错误统计 |

**测量示例**:

```bash
# 延迟测量
opa eval --bench --count 1000 'data.policy.allow'

# 输出示例
+--------------------+----------------+
| samples            | 1000           |
| mean (ns/op)       | 1,234,567      |
| P50 (ns/op)        | 1,100,000      |
| P90 (ns/op)        | 1,800,000      |
| P99 (ns/op)        | 2,500,000      |
+--------------------+----------------+
```

### 1.2 剖析方法论

**USE方法** (Utilization, Saturation, Errors):

1. **Utilization**: 资源使用率（CPU、内存、网络）
2. **Saturation**: 资源饱和度（队列长度、等待时间）
3. **Errors**: 错误率

**RED方法** (Rate, Errors, Duration):

1. **Rate**: 请求速率
2. **Errors**: 错误率
3. **Duration**: 延迟分布

### 1.3 优化流程

```text
1. 测量 (Measure)
   ├─ 建立基准
   ├─ 识别瓶颈
   └─ 量化影响

2. 分析 (Analyze)
   ├─ CPU profiling
   ├─ 内存profiling
   └─ 查询分析

3. 优化 (Optimize)
   ├─ 代码优化
   ├─ 算法优化
   └─ 配置调优

4. 验证 (Verify)
   ├─ A/B测试
   ├─ 压力测试
   └─ 生产验证

5. 重复
```

---

## 2. 剖析工具

### 2.1 OPA内置工具

**1. `--explain` 模式**:

```bash
# 查看求值过程
opa eval --explain=full --data policy.rego 'data.policy.allow'

# 输出示例
Enter data.policy.allow
| Enter data.policy.is_admin
| | Note "input.user = alice"
| | Note "data.admins[alice] exists"
| | Exit data.policy.is_admin
| Redo data.policy.is_admin
Exit data.policy.allow
```

**2. `--metrics` 模式**:

```bash
# 收集性能指标
opa eval --metrics --data policy.rego 'data.policy.allow'

# 输出示例
{
  "metrics": {
    "timer_rego_query_eval_ns": 1234567,
    "timer_rego_query_compile_ns": 234567,
    "timer_rego_builtin_http_send_ns": 456789,
    "counter_rego_query_eval": 1
  }
}
```

**3. `--bench` 模式**:

```bash
# 基准测试
opa eval --bench --count 10000 'data.policy.allow'
```

### 2.2 Go Profiling工具

**启用OPA profiling**:

```bash
# 启动OPA服务器并启用profiling
opa run --server --addr :8181 --diagnostic-addr :8282 \
    --set decision_logs.console=true

# CPU profiling
curl http://localhost:8282/debug/pprof/profile?seconds=30 > cpu.prof

# 内存profiling
curl http://localhost:8282/debug/pprof/heap > mem.prof

# Goroutine profiling
curl http://localhost:8282/debug/pprof/goroutine > goroutine.prof
```

**分析Profile**:

```bash
# 使用go tool pprof
go tool pprof cpu.prof

# 命令行交互
(pprof) top10        # 显示top 10函数
(pprof) list <func>  # 显示函数详情
(pprof) web          # 生成图形（需要graphviz）

# 生成火焰图
go tool pprof -http=:8080 cpu.prof
```

### 2.3 第三方工具

**1. Grafana + Prometheus**:

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'opa'
    static_configs:
      - targets: ['localhost:8181']
    metrics_path: '/metrics'
```

**2. Jaeger（分布式追踪）**:

```bash
# 启用追踪
opa run --server \
    --set distributed_tracing.type=jaeger \
    --set distributed_tracing.address=localhost:6831
```

**3. wrk/ab（压测工具）**:

```bash
# wrk压测
wrk -t4 -c100 -d30s --latency \
    -s test.lua http://localhost:8181/v1/data/policy/allow

# Apache Bench
ab -n 10000 -c 100 http://localhost:8181/v1/data/policy/allow
```

---

## 3. 基准测试

### 3.1 建立Baseline

**基准测试脚本**:

```bash
#!/bin/bash
# benchmark.sh

echo "=== OPA Performance Baseline ==="
echo "Date: $(date)"
echo "OPA Version: $(opa version)"
echo ""

# 测试1：简单查询
echo "Test 1: Simple Query"
opa eval --bench --count 10000 \
    --data policy.rego \
    'data.policy.allow' \
    --input <(echo '{"user": "alice"}')

# 测试2：复杂查询
echo ""
echo "Test 2: Complex Query"
opa eval --bench --count 1000 \
    --data complex_policy.rego \
    'data.policy.allow' \
    --input complex_input.json

# 测试3：大数据集
echo ""
echo "Test 3: Large Dataset"
opa eval --bench --count 100 \
    --data policy.rego \
    --bundle large_bundle.tar.gz \
    'data.policy.allow' \
    --input input.json
```

**记录结果**:

```text
=== Baseline Results ===
Date: 2025-10-23
OPA Version: 0.58.0

Test 1: Simple Query
- Mean: 0.5ms
- P50: 0.4ms
- P99: 1.2ms
- Throughput: 2000 req/s

Test 2: Complex Query
- Mean: 15ms
- P50: 12ms
- P99: 35ms
- Throughput: 66 req/s

Test 3: Large Dataset
- Mean: 150ms
- P50: 140ms
- P99: 200ms
- Throughput: 6.6 req/s
```

### 3.2 压力测试

**wrk脚本**:

```lua
-- test.lua
wrk.method = "POST"
wrk.headers["Content-Type"] = "application/json"
wrk.body = [[
{
  "input": {
    "user": "alice",
    "resource": "/api/data",
    "action": "read"
  }
}
]]

-- 收集延迟统计
done = function(summary, latency, requests)
    io.write("Latency Distribution:\n")
    for _, p in pairs({ 50, 75, 90, 99, 99.9 }) do
        n = latency:percentile(p)
        io.write(string.format("  %g%%: %d μs\n", p, n))
    end
end
```

**运行压测**:

```bash
# 逐步增加负载
for concurrent in 10 50 100 500 1000; do
    echo "Testing with $concurrent concurrent connections"
    wrk -t4 -c$concurrent -d30s --latency \
        -s test.lua http://localhost:8181/v1/data/policy/allow
    sleep 5
done
```

### 3.3 A/B测试

**对比优化前后**:

```bash
#!/bin/bash

echo "=== A/B Performance Test ==="

# 版本A（优化前）
echo "Version A (Before Optimization):"
opa eval --bench --count 1000 \
    --data policy_v1.rego \
    'data.policy.allow' > results_a.txt

# 版本B（优化后）
echo "Version B (After Optimization):"
opa eval --bench --count 1000 \
    --data policy_v2.rego \
    'data.policy.allow' > results_b.txt

# 对比
echo ""
echo "Performance Improvement:"
python3 compare.py results_a.txt results_b.txt
```

---

## 4. CPU剖析

### 4.1 CPU Profiling

**收集CPU Profile**:

```bash
# 方法1：通过HTTP端点
curl http://localhost:8282/debug/pprof/profile?seconds=30 > cpu.prof

# 方法2：在测试中
go test -cpuprofile=cpu.prof -bench=.

# 方法3：编程方式
```go
import "runtime/pprof"

f, _ := os.Create("cpu.prof")
pprof.StartCPUProfile(f)
defer pprof.StopCPUProfile()
// ... 运行代码 ...
```

### 4.2 火焰图分析

**生成火焰图**:

```bash
# 使用go tool pprof
go tool pprof -http=:8080 cpu.prof

# 浏览器打开 http://localhost:8080
# 查看 "Flame Graph" 视图
```

**解读火焰图**:

```text
火焰图解读：
- X轴：CPU时间占比（宽度 = 时间占比）
- Y轴：调用栈深度
- 颜色：随机（无特殊含义）
- 平顶：热点函数（CPU消耗多）
- 突出的塔：深调用栈

示例热点：
┌────────────────────────────────────────┐
│   main (100%)                          │
├────────────────────────────────────────┤
│   eval (95%)                           │
├─────────────────────┬──────────────────┤
│   unify (50%)       │  index (45%)     │
├──────┬──────────────┼──────────────────┤
│occurs│ bind (30%)   │  lookup (40%)    │  ← 热点！
└──────┴──────────────┴──────────────────┘
```

### 4.3 热点函数优化

**案例：优化Unify函数**:

**优化前**:

```go
func Unify(s, t Term) (*Substitution, error) {
    // 每次都创建新map
    theta := make(map[Var]Term)
    
    // 递归统一
    if err := unifyHelper(s, t, theta); err != nil {
        return nil, err
    }
    
    return &Substitution{theta}, nil
}
```

**性能分析**:

```text
CPU Profile:
  50% - Unify函数
  30%   - map创建和分配
  15%   - 递归调用开销
  5%    - 类型断言
```

**优化后**:

```go
// 使用对象池
var substPool = sync.Pool{
    New: func() interface{} {
        return &Substitution{
            bindings: make(map[Var]Term, 16),  // 预分配
        }
    },
}

func Unify(s, t Term) (*Substitution, error) {
    // 从池中获取
    theta := substPool.Get().(*Substitution)
    theta.Reset()
    
    if err := unifyHelper(s, t, theta); err != nil {
        substPool.Put(theta)  // 归还池
        return nil, err
    }
    
    return theta, nil
}
```

**优化效果**:

```text
优化前: 1,500 ns/op, 800 B/op, 15 allocs/op
优化后:   800 ns/op, 200 B/op,  3 allocs/op
提升:    46%性能提升, 75%内存减少
```

---

## 5. 内存剖析

### 5.1 内存Profiling

**收集内存Profile**:

```bash
# 堆内存
curl http://localhost:8282/debug/pprof/heap > heap.prof

# 分析
go tool pprof heap.prof

(pprof) top10           # Top 10内存分配
(pprof) list <func>     # 函数详情
(pprof) web             # 可视化
```

**解读输出**:

```text
Showing nodes accounting for 1024MB, 80% of 1280MB total
      flat  flat%   sum%        cum   cum%
   512MB 40.00% 40.00%    512MB 40.00%  makeSlice
   256MB 20.00% 60.00%    768MB 60.00%  buildIndex
   128MB 10.00% 70.00%    128MB 10.00%  copyMap
   128MB 10.00% 80.00%    256MB 20.00%  parseRules
```

### 5.2 内存泄漏检测

**检测方法**:

```bash
# 1. 运行时监控内存增长
watch -n 1 'ps -o rss= -p $(pgrep opa)'

# 2. 比较不同时间点的内存快照
curl http://localhost:8282/debug/pprof/heap > heap1.prof
# ... 运行一段时间 ...
curl http://localhost:8282/debug/pprof/heap > heap2.prof

# 对比
go tool pprof -base heap1.prof heap2.prof
```

**常见泄漏场景**:

```go
// 泄漏1：未关闭的goroutine
func leakyEval() {
    ch := make(chan Result)
    go func() {
        // 如果ch没有接收者，goroutine永远不会退出
        ch <- compute()
    }()
    // 忘记 <-ch 或 close(ch)
}

// 修复
func fixedEval() {
    ch := make(chan Result, 1)  // 缓冲channel
    go func() {
        ch <- compute()
    }()
    select {
    case result := <-ch:
        return result
    case <-time.After(timeout):
        return nil
    }
}

// 泄漏2：全局cache无限增长
var cache = make(map[string]interface{})

func cacheGet(key string) interface{} {
    if val, ok := cache[key]; ok {
        return val
    }
    val := compute(key)
    cache[key] = val  // 永不清理！
    return val
}

// 修复：使用LRU
import "github.com/hashicorp/golang-lru"

var cache, _ = lru.New(10000)  // 限制大小
```

### 5.3 GC优化

**调优GC**:

```bash
# 设置GOGC（默认100）
export GOGC=200  # 减少GC频率，增加内存使用

# 设置GOMEMLIMIT（Go 1.19+）
export GOMEMLIMIT=4GiB  # 软内存限制
```

**GC追踪**:

```bash
# 启用GC trace
GODEBUG=gctrace=1 opa run --server

# 输出示例
gc 1 @0.123s 5%: 0.018+1.2+0.015 ms clock, 0.14+0.35/1.1/2.1+0.12 ms cpu, 4->5->3 MB, 6 MB goal, 8 P
```

**解读**:

- `4->5->3 MB`: 堆大小变化（GC前 -> GC后 -> 存活对象）
- `6 MB goal`: 下次GC触发阈值
- `0.018+1.2+0.015 ms clock`: STW+并发+STW时间

---

## 6. 查询优化

### 6.1 查询计划分析

**查看查询计划**:

```bash
# 详细解释模式
opa eval --explain=full --format=pretty \
    --data policy.rego \
    'data.policy.allow'
```

**输出示例**:

```text
Query Plan:
1. eval data.policy.allow
   a. eval input.user = x
   b. eval data.admins[x]  ← 使用索引！
   c. eval input.action = "write"
   d. eval data.permissions[x]["write"]  ← 使用索引！

Index Usage:
- data.admins: hash index (O(1))
- data.permissions: nested index (O(1))

Estimated Cost: 5 units
```

### 6.2 索引优化

**案例：添加索引**:

**优化前**:

```rego
# 无索引，需要全扫描
allowed_users[user] {
    some user in data.users
    data.roles[data.users[user].role].permissions[input.resource]
}
```

**性能**: O(n) 其中n=用户数

**优化：重组数据**:

```rego
# 优化后：按resource索引
allowed_users[user] {
    some user in data.resource_permissions[input.resource]
}
```

**数据结构**:

```json
{
  "resource_permissions": {
    "/api/data": ["alice", "bob"],
    "/api/admin": ["admin"]
  }
}
```

**性能**: O(1)

**性能对比**:

| 用户数 | 优化前 | 优化后 | 提升 |
|--------|--------|--------|------|
| 100 | 10ms | 0.1ms | 100x |
| 1,000 | 100ms | 0.1ms | 1000x |
| 10,000 | 1000ms | 0.1ms | 10000x |

### 6.3 部分求值

**启用部分求值**:

```bash
# 编译时部分求值
opa build --partial \
    --unknown-data 'input' \
    --unknown-data 'data.dynamic_config' \
    policy.rego

# 结果：生成优化后的策略
```

**示例**:

**原始策略**:

```rego
allow {
    input.user == "alice"
    data.static_config.feature_enabled
    data.dynamic_config.quota > 0
}
```

**部分求值后** (假设`data.static_config.feature_enabled = true`):

```rego
allow {
    input.user == "alice"
    data.dynamic_config.quota > 0
}
```

**优化效果**: 消除静态已知的检查

---

## 7. 实战案例

### 7.1 慢查询优化

**问题**: 查询延迟P99达到500ms

**步骤1：Profile**:

```bash
opa eval --metrics --explain=full 'data.policy.allow'
```

**发现**: 遍历10,000个用户

**步骤2：分析查询**:

```rego
# 慢查询
allow {
    some user in data.users           # 遍历10,000个用户
    user.manager == input.user
    user.department == input.department
}
```

**步骤3：优化**:

```rego
# 优化方案1：反向索引
allow {
    managed_by[input.user][_]  # 使用索引
}

managed_by[manager] := users {
    users := [user |
        some user in data.users
        user.manager == manager
    ]
}

# 优化方案2：预计算
# 在Bundle构建时预计算管理关系
```

**步骤4：验证**:

```bash
# 对比性能
opa eval --bench --count 1000 'data.policy.allow'
```

**结果**:

- 优化前: P99=500ms
- 优化后: P99=5ms
- **提升100倍！**

### 7.2 高并发场景

**问题**: 1000并发时CPU 100%

**Profile分析**:

```text
CPU Profile Top 10:
  35% - sync.(*RWMutex).RLock
  20% - storage.Read
  15% - json.Unmarshal
  10% - ast.Value.Compare
  ...
```

**发现**: 读锁争用

**优化方案**:

```go
// 优化前：粗粒度锁
type Storage struct {
    mu   sync.RWMutex
    data map[string]interface{}
}

func (s *Storage) Read(path string) (interface{}, error) {
    s.mu.RLock()
    defer s.mu.RUnlock()
    // 长时间持有锁
    return deepCopy(s.data[path]), nil
}

// 优化后：细粒度锁 + COW
type Storage struct {
    current atomic.Value  // *Snapshot
}

type Snapshot struct {
    data map[string]interface{}  // 不可变
}

func (s *Storage) Read(path string) (interface{}, error) {
    // 无锁读取
    snapshot := s.current.Load().(*Snapshot)
    return snapshot.data[path], nil
}
```

**结果**:

- 优化前: 500 req/s @ 1000并发
- 优化后: 5,000 req/s @ 1000并发
- **提升10倍！**

### 7.3 大数据集优化

**问题**: 100MB数据包导致OOM

**Profile**:

```text
Memory Profile:
  80% - storage.InMemoryStore
  15% - ast.Term.Copy
  5% - json.Unmarshal
```

**优化方案**:

1. **数据分片**:

    ```bash
    # 将大Bundle分成多个小Bundle
    split-bundle.sh large-bundle.tar.gz \
        --shards 10 \
        --output shards/
    ```

2. **按需加载**:

    ```go
    // 懒加载数据
    type LazyStore struct {
        loaded map[string]bool
        loader DataLoader
    }

    func (s *LazyStore) Read(path string) (interface{}, error) {
        shard := s.getShard(path)
        if !s.loaded[shard] {
            s.loader.Load(shard)
            s.loaded[shard] = true
        }
        return s.data[path], nil
    }
    ```

3. **使用外部存储**:

    ```yaml
    # 使用数据库
    storage:
    type: postgres
    connection: "postgres://..."
    cache:
        enabled: true
        size: 100MB
    ```

**结果**:

- 优化前: 内存2GB，启动60s
- 优化后: 内存500MB，启动5s
- **内存减少75%，启动快12倍！**

---

## 8. 监控与告警

### 8.1 指标收集

**Prometheus指标**:

```yaml
# opa-config.yaml
decision_logs:
  plugin: prometheus

status:
  plugin: prometheus
  prometheus:
    port: 9182
```

**关键指标**:

```promql
# 请求延迟
histogram_quantile(0.99, rate(http_request_duration_milliseconds_bucket[5m]))

# 吞吐量
rate(http_requests_total[1m])

# 错误率
rate(http_requests_total{code=~"5.."}[1m]) / rate(http_requests_total[1m])

# CPU使用率
rate(process_cpu_seconds_total[1m])

# 内存使用
process_resident_memory_bytes
```

### 8.2 监控仪表板

**Grafana Dashboard**:

```json
{
  "dashboard": {
    "title": "OPA Performance",
    "panels": [
      {
        "title": "Request Latency",
        "targets": [{
          "expr": "histogram_quantile(0.99, rate(http_request_duration_milliseconds_bucket[5m]))"
        }],
        "type": "graph"
      },
      {
        "title": "Throughput",
        "targets": [{
          "expr": "rate(http_requests_total[1m])"
        }],
        "type": "graph"
      },
      {
        "title": "Error Rate",
        "targets": [{
          "expr": "rate(http_requests_total{code=~\"5..\"}[1m]) / rate(http_requests_total[1m])"
        }],
        "type": "graph"
      }
    ]
  }
}
```

### 8.3 告警策略

**Alertmanager规则**:

```yaml
groups:
  - name: opa_alerts
    rules:
      # 高延迟告警
      - alert: OPAHighLatency
        expr: histogram_quantile(0.99, rate(http_request_duration_milliseconds_bucket[5m])) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "OPA P99 latency is high"
          description: "P99 latency is {{ $value }}ms"
      
      # 高错误率告警
      - alert: OPAHighErrorRate
        expr: rate(http_requests_total{code=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.01
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "OPA error rate is high"
          description: "Error rate is {{ $value | humanizePercentage }}"
      
      # 内存使用告警
      - alert: OPAHighMemory
        expr: process_resident_memory_bytes > 2e9
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "OPA memory usage is high"
          description: "Memory usage is {{ $value | humanize }}B"
```

---

## 9. 生产优化

### 9.1 配置调优

**OPA配置**:

```yaml
# config.yaml
server:
  # 调整服务器参数
  max_body_size: 10485760  # 10MB
  read_timeout: 10s
  write_timeout: 10s

caches:
  # 启用缓存
  inter_query_builtin_cache:
    max_size_bytes: 104857600  # 100MB

bundles:
  # Bundle配置
  authz:
    service: bundle_service
    resource: bundles/authz.tar.gz
    polling:
      min_delay_seconds: 60
      max_delay_seconds: 120

# Go运行时调优
GOGC: 200  # 减少GC频率
GOMAXPROCS: 8  # 并发数
GOMEMLIMIT: 4GiB  # 内存限制
```

### 9.2 缓存策略

**多层缓存**:

```text
┌─────────────────────────────────────┐
│  L1: Query Result Cache (内存)      │
│  Size: 10MB, TTL: 60s               │
├─────────────────────────────────────┤
│  L2: Compiled Query Cache (内存)    │
│  Size: 50MB, LRU                    │
├─────────────────────────────────────┤
│  L3: Data Cache (内存/Redis)        │
│  Size: 500MB, TTL: 300s             │
├─────────────────────────────────────┤
│  L4: Bundle Cache (磁盘)            │
│  Size: Unlimited                    │
└─────────────────────────────────────┘
```

**实现**:

```go
type CachedEvaluator struct {
    l1 *QueryCache    // 查询结果缓存
    l2 *CompiledCache // 编译缓存
    l3 *DataCache     // 数据缓存
}

func (ce *CachedEvaluator) Eval(query string, input interface{}) (interface{}, error) {
    // L1: 查询结果缓存
    key := ce.cacheKey(query, input)
    if result, ok := ce.l1.Get(key); ok {
        return result, nil
    }
    
    // L2: 编译缓存
    compiled, ok := ce.l2.Get(query)
    if !ok {
        compiled = ce.compile(query)
        ce.l2.Set(query, compiled)
    }
    
    // 执行
    result, err := ce.eval(compiled, input)
    if err != nil {
        return nil, err
    }
    
    // 缓存结果
    ce.l1.Set(key, result)
    
    return result, nil
}
```

### 9.3 扩展方案

**水平扩展**:

```yaml
# Kubernetes部署
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opa
spec:
  replicas: 10  # 扩展到10个副本
  template:
    spec:
      containers:
      - name: opa
        image: openpolicyagent/opa:latest
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "2000m"
            memory: "2Gi"
        livenessProbe:
          httpGet:
            path: /health
            port: 8181
        readinessProbe:
          httpGet:
            path: /health?bundle=true
            port: 8181
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: opa-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: opa
  minReplicas: 5
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Pods
    pods:
      metric:
        name: http_request_duration_p99
      target:
        type: AverageValue
        averageValue: "50m"  # 50ms
```

---

## 10. 最佳实践

### 10.1 优化清单

**性能优化检查清单**:

- [ ] 建立性能基准
- [ ] 启用CPU/内存profiling
- [ ] 分析查询计划
- [ ] 优化热点函数
- [ ] 添加适当索引
- [ ] 启用缓存
- [ ] 使用部分求值
- [ ] 优化数据结构
- [ ] 减少内存分配
- [ ] 调优GC参数
- [ ] 设置资源限制
- [ ] 配置监控告警
- [ ] 压力测试验证
- [ ] 文档优化措施

### 10.2 反模式避免

**常见性能反模式**:

❌ **反模式1：全表扫描**

```rego
# Bad
users_in_dept[user] {
    some user in data.users  # 扫描所有用户
    user.dept == input.dept
}

# Good: 使用索引
users_in_dept := data.departments[input.dept].users
```

❌ **反模式2：重复计算**

```rego
# Bad
allow {
    expensive_computation(input) == true
    expensive_computation(input) > 0  # 重复计算！
}

# Good: 缓存结果
allow {
    result := expensive_computation(input)
    result == true
    result > 0
}
```

❌ **反模式3：深度嵌套**

```rego
# Bad: O(n^4)
result {
    some i
    some j
    some k
    some l
    data.a[i].b[j].c[k].d[l] == input.value
}

# Good: 使用索引 O(1)
result {
    input.value in data.indexed_values
}
```

### 10.3 持续改进

**性能优化流程**:

```text
1. 监控生产性能
   ↓
2. 识别性能问题
   ↓
3. Profile分析根因
   ↓
4. 实施优化方案
   ↓
5. A/B测试验证
   ↓
6. 灰度发布
   ↓
7. 全量上线
   ↓
8. 持续监控
   ↓
(循环)
```

---

## 附录

### A. 工具参考

| 工具 | 用途 | 安装 |
|------|------|------|
| **opa** | 策略求值、profiling | [官网](https://www.openpolicyagent.org/docs/latest/#running-opa) |
| **pprof** | Go profiling分析 | 内置 |
| **wrk** | HTTP压测 | `brew install wrk` |
| **Prometheus** | 指标收集 | [官网](https://prometheus.io/) |
| **Grafana** | 可视化 | [官网](https://grafana.com/) |
| **Jaeger** | 分布式追踪 | [官网](https://www.jaegertracing.io/) |

### B. 性能检查清单

```markdown
## 性能审查清单

### 代码层面
- [ ] 无全表扫描
- [ ] 无重复计算
- [ ] 使用适当索引
- [ ] 避免深度嵌套
- [ ] 使用高效数据结构

### 配置层面
- [ ] GOGC已调优
- [ ] 缓存已启用
- [ ] 资源限制已设置
- [ ] 超时参数合理

### 监控层面
- [ ] 延迟监控已配置
- [ ] 吞吐量监控已配置
- [ ] 错误率监控已配置
- [ ] 告警规则已设置

### 测试层面
- [ ] 基准测试已建立
- [ ] 压力测试已完成
- [ ] 性能回归测试已通过
```

### C. 优化案例库

**案例1: RBAC查询优化**:

- 优化前: 50ms
- 优化后: 0.5ms
- 技术: 反向索引
- 提升: 100x

**案例2: 大数据集加载**:

- 优化前: 60s启动, 2GB内存
- 优化后: 5s启动, 500MB内存
- 技术: 懒加载、分片
- 提升: 12x启动速度, 75%内存减少

**案例3: 高并发场景**:

- 优化前: 500 req/s
- 优化后: 5000 req/s
- 技术: 无锁数据结构、COW
- 提升: 10x吞吐量

---

**文档版本**: v1.0  
**最后更新**: 2025年10月23日  
**维护者**: OPA技术文档项目

**相关阅读**:

- [性能优化指南](../05-最佳实践/05.6-性能优化指南.md) - 优化建议
- [查询优化算法](../11-算法深度/11.4-查询优化算法.md) - 算法理论
- [并发控制机制](../11-算法深度/11.5-并发控制机制.md) - 并发优化
- [索引数据结构](../11-算法深度/11.3-索引数据结构.md) - 索引优化
