# è¯æ³•å™¨ä¸è¯­æ³•è§£æå™¨å®ç°

> **æ–‡æ¡£ç±»å‹**: æºç å®ç°åˆ†æ  
> **æ ¸å¿ƒæ¨¡å—**: `ast/parser.go`, `ast/scanner.go`  
> **é€‚ç”¨è¯»è€…**: ç¼–è¯‘å™¨å¼€å‘è€…ã€è¯­è¨€è®¾è®¡è€…ã€æ·±åº¦å­¦ä¹ è€…  
> **å…ˆä¿®çŸ¥è¯†**: [Regoè¯­æ³•è§„èŒƒ](../02-è¯­è¨€æ¨¡å‹/02.1-Regoè¯­æ³•è§„èŒƒ.md)ã€ç¼–è¯‘åŸç†åŸºç¡€  
> **æœ€åæ›´æ–°**: 2025å¹´10æœˆ23æ—¥  
> **æ–‡æ¡£çŠ¶æ€**: âœ… Phase 2.2 - è§£æå™¨å®ç°  
> **OPAç‰ˆæœ¬**: v0.68.0

---

## ğŸ¯ å®ç°åˆ†æè¯´æ˜

> **æœ¬æ–‡æ¡£ç›®æ ‡**:
>
> - âœ… æ·±å…¥ç†è§£OPAè¯æ³•åˆ†æå™¨çš„å®ç°åŸç†
> - âœ… æŒæ¡æ‰‹å†™é€’å½’ä¸‹é™è§£æå™¨çš„è®¾è®¡æ¨¡å¼
> - âœ… åˆ†æRegoè¯­æ³•è§£æçš„å…³é”®æŠ€æœ¯ç‚¹
> - âœ… å­¦ä¹ é”™è¯¯æ¢å¤å’Œé”™è¯¯æŠ¥å‘Šæœºåˆ¶
>
> **æŠ€æœ¯äº®ç‚¹**:
>
> - **æ‰‹å†™Scanner**: é«˜æ•ˆçš„å­—ç¬¦æµå¤„ç†
> - **é€’å½’ä¸‹é™Parser**: æ¸…æ™°çš„è¯­æ³•ç»“æ„æ˜ å°„
> - **é”™è¯¯æ¢å¤**: ç”Ÿäº§çº§çš„é”™è¯¯å¤„ç†
> - **ä½ç½®è¿½è¸ª**: ç²¾ç¡®çš„æºç å®šä½
>
> **å®æˆ˜ä»·å€¼**:
>
> - å­¦ä¹ ç¼–è¯‘å™¨å‰ç«¯è®¾è®¡
> - ç†è§£DSLè§£æå®ç°
> - æŒæ¡é”™è¯¯å¤„ç†æœ€ä½³å®è·µ
> - ä¸ºè¯­è¨€æ‰©å±•æ‰“åŸºç¡€

---

## ç›®å½•

- [è¯æ³•å™¨ä¸è¯­æ³•è§£æå™¨å®ç°](#è¯æ³•å™¨ä¸è¯­æ³•è§£æå™¨å®ç°)
  - [ğŸ¯ å®ç°åˆ†æè¯´æ˜](#-å®ç°åˆ†æè¯´æ˜)
  - [ç›®å½•](#ç›®å½•)
  - [1. è§£æå™¨æ¶æ„æ€»è§ˆ](#1-è§£æå™¨æ¶æ„æ€»è§ˆ)
    - [1.1 æ•´ä½“æ¶æ„](#11-æ•´ä½“æ¶æ„)
    - [1.2 æ ¸å¿ƒæ•°æ®ç»“æ„](#12-æ ¸å¿ƒæ•°æ®ç»“æ„)
    - [1.3 è§£ææµç¨‹](#13-è§£ææµç¨‹)
  - [2. è¯æ³•åˆ†æå™¨ï¼ˆScannerï¼‰](#2-è¯æ³•åˆ†æå™¨scanner)
    - [2.1 Scannerç»“æ„](#21-scannerç»“æ„)
    - [2.2 Tokenå®šä¹‰](#22-tokenå®šä¹‰)
    - [2.3 è¯æ³•æ‰«æå®ç°](#23-è¯æ³•æ‰«æå®ç°)
    - [2.4 å…³é”®å­—è¯†åˆ«](#24-å…³é”®å­—è¯†åˆ«)
    - [2.5 å­—ç¬¦ä¸²ä¸è½¬ä¹‰](#25-å­—ç¬¦ä¸²ä¸è½¬ä¹‰)
    - [2.6 æ•°å­—è§£æ](#26-æ•°å­—è§£æ)
  - [3. è¯­æ³•è§£æå™¨ï¼ˆParserï¼‰](#3-è¯­æ³•è§£æå™¨parser)
    - [3.1 Parserç»“æ„](#31-parserç»“æ„)
    - [3.2 é€’å½’ä¸‹é™è§£æ](#32-é€’å½’ä¸‹é™è§£æ)
    - [3.3 æ¨¡å—è§£æ](#33-æ¨¡å—è§£æ)
    - [3.4 è§„åˆ™è§£æ](#34-è§„åˆ™è§£æ)
    - [3.5 è¡¨è¾¾å¼è§£æ](#35-è¡¨è¾¾å¼è§£æ)
    - [3.6 é¡¹ï¼ˆTermï¼‰è§£æ](#36-é¡¹termè§£æ)
  - [4. è¿ç®—ç¬¦ä¼˜å…ˆçº§](#4-è¿ç®—ç¬¦ä¼˜å…ˆçº§)
    - [4.1 ä¼˜å…ˆçº§è¡¨](#41-ä¼˜å…ˆçº§è¡¨)
    - [4.2 è¡¨è¾¾å¼è§£æç®—æ³•](#42-è¡¨è¾¾å¼è§£æç®—æ³•)
    - [4.3 Pratt Parsing](#43-pratt-parsing)
  - [5. é”™è¯¯å¤„ç†](#5-é”™è¯¯å¤„ç†)
    - [5.1 é”™è¯¯ç±»å‹](#51-é”™è¯¯ç±»å‹)
    - [5.2 é”™è¯¯æ¢å¤ç­–ç•¥](#52-é”™è¯¯æ¢å¤ç­–ç•¥)
    - [5.3 é”™è¯¯æŠ¥å‘Š](#53-é”™è¯¯æŠ¥å‘Š)
    - [5.4 ä½ç½®è¿½è¸ª](#54-ä½ç½®è¿½è¸ª)
  - [6. ç‰¹æ®Šè¯­æ³•å¤„ç†](#6-ç‰¹æ®Šè¯­æ³•å¤„ç†)
    - [6.1 é›†åˆæ¨å¯¼å¼](#61-é›†åˆæ¨å¯¼å¼)
    - [6.2 å¯¹è±¡æ¨å¯¼å¼](#62-å¯¹è±¡æ¨å¯¼å¼)
    - [6.3 æ•°ç»„æ¨å¯¼å¼](#63-æ•°ç»„æ¨å¯¼å¼)
    - [6.4 å¼•ç”¨ï¼ˆReferenceï¼‰](#64-å¼•ç”¨reference)
    - [6.5 å‡½æ•°è°ƒç”¨](#65-å‡½æ•°è°ƒç”¨)
  - [7. æºç å®ç°åˆ†æ](#7-æºç å®ç°åˆ†æ)
    - [7.1 Scanneræ ¸å¿ƒä»£ç ](#71-scanneræ ¸å¿ƒä»£ç )
    - [7.2 Parseræ ¸å¿ƒä»£ç ](#72-parseræ ¸å¿ƒä»£ç )
    - [7.3 æ€§èƒ½ä¼˜åŒ–](#73-æ€§èƒ½ä¼˜åŒ–)
  - [8. å®æˆ˜ç¤ºä¾‹](#8-å®æˆ˜ç¤ºä¾‹)
    - [8.1 ç®€å•è§„åˆ™è§£æ](#81-ç®€å•è§„åˆ™è§£æ)
    - [8.2 å¤æ‚è¡¨è¾¾å¼è§£æ](#82-å¤æ‚è¡¨è¾¾å¼è§£æ)
    - [8.3 é”™è¯¯å¤„ç†ç¤ºä¾‹](#83-é”™è¯¯å¤„ç†ç¤ºä¾‹)
  - [9. æµ‹è¯•ä¸éªŒè¯](#9-æµ‹è¯•ä¸éªŒè¯)
    - [9.1 å•å…ƒæµ‹è¯•](#91-å•å…ƒæµ‹è¯•)
    - [9.2 æ€§èƒ½æµ‹è¯•](#92-æ€§èƒ½æµ‹è¯•)
    - [9.3 Fuzzingæµ‹è¯•](#93-fuzzingæµ‹è¯•)
  - [é™„å½•](#é™„å½•)
    - [A. Tokenå®Œæ•´åˆ—è¡¨](#a-tokenå®Œæ•´åˆ—è¡¨)
    - [B. è¯­æ³•è§„åˆ™BNF](#b-è¯­æ³•è§„åˆ™bnf)
    - [C. è°ƒè¯•å·¥å…·](#c-è°ƒè¯•å·¥å…·)

---

## 1. è§£æå™¨æ¶æ„æ€»è§ˆ

### 1.1 æ•´ä½“æ¶æ„

OPAçš„è§£æå™¨é‡‡ç”¨**ä¸¤é˜¶æ®µè®¾è®¡**ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Regoæºä»£ç  (å­—ç¬¦ä¸²)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         é˜¶æ®µ1: è¯æ³•åˆ†æ (Scanner)           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  å­—ç¬¦æµ â†’ Tokenæµ                  â”‚    â”‚
â”‚  â”‚  - è·³è¿‡ç©ºç™½                         â”‚    â”‚
â”‚  â”‚  - è¯†åˆ«å…³é”®å­—                       â”‚    â”‚
â”‚  â”‚  - è§£æå­—é¢é‡                       â”‚    â”‚
â”‚  â”‚  - ä½ç½®è¿½è¸ª                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
       Tokenæµ: [PACKAGE, IDENT, ...]
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         é˜¶æ®µ2: è¯­æ³•åˆ†æ (Parser)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Tokenæµ â†’ AST                      â”‚    â”‚
â”‚  â”‚  - é€’å½’ä¸‹é™è§£æ                     â”‚    â”‚
â”‚  â”‚  - æ„å»ºASTèŠ‚ç‚¹                      â”‚    â”‚
â”‚  â”‚  - è¯­æ³•éªŒè¯                         â”‚    â”‚
â”‚  â”‚  - é”™è¯¯æ¢å¤                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
          AST (æŠ½è±¡è¯­æ³•æ ‘)
```

### 1.2 æ ¸å¿ƒæ•°æ®ç»“æ„

**ScannerçŠ¶æ€**:

```go
// scanner: è¯æ³•åˆ†æå™¨
type scanner struct {
    source   []byte    // æºä»£ç 
    offset   int       // å½“å‰ä½ç½®
    ch       rune      // å½“å‰å­—ç¬¦
    lineNum  int       // è¡Œå·
    linePos  int       // è¡Œå†…ä½ç½®
    
    // é”™è¯¯æ”¶é›†
    errors   Errors
}
```

**ParserçŠ¶æ€**:

```go
// parser: è¯­æ³•åˆ†æå™¨
type parser struct {
    s        *scanner  // è¯æ³•åˆ†æå™¨
    tok      token     // å½“å‰token
    tokVal   string    // tokenå€¼
    
    // ASTæ„å»º
    module   *Module   // å½“å‰æ¨¡å—
    
    // é”™è¯¯æ¢å¤
    panicMode bool
    errors    Errors
}
```

**Tokenå®šä¹‰**:

```go
// token: è¯æ³•å•å…ƒç±»å‹
type token int

const (
    // ç‰¹æ®Štoken
    ILLEGAL token = iota
    EOF
    COMMENT
    
    // å­—é¢é‡
    IDENT      // user, allow
    NUMBER     // 123, 3.14
    STRING     // "hello"
    
    // å…³é”®å­—
    PACKAGE    // package
    IMPORT     // import
    AS         // as
    DEFAULT    // default
    IF         // if
    ELSE       // else
    
    // è¿ç®—ç¬¦
    ASSIGN     // :=
    EQ         // ==
    NEQ        // !=
    LT         // <
    GT         // >
    
    // åˆ†éš”ç¬¦
    LPAREN     // (
    RPAREN     // )
    LBRACK     // [
    RBRACK     // ]
    LBRACE     // {
    RBRACE     // }
    // ...
)
```

### 1.3 è§£ææµç¨‹

**å®Œæ•´è§£ææµç¨‹**:

```go
// ParseModule: è§£æRegoæ¨¡å—
func ParseModule(filename string, input []byte) (*Module, error) {
    // 1. åˆ›å»ºscanner
    s := newScanner(input)
    
    // 2. åˆ›å»ºparser
    p := newParser(s)
    
    // 3. è§£ææ¨¡å—
    module := p.parseModule()
    
    // 4. æ£€æŸ¥é”™è¯¯
    if len(p.errors) > 0 {
        return nil, p.errors
    }
    
    return module, nil
}
```

---

## 2. è¯æ³•åˆ†æå™¨ï¼ˆScannerï¼‰

### 2.1 Scannerç»“æ„

**å®Œæ•´å®ç°**:

```go
// scanner: è¯æ³•åˆ†æå™¨
type scanner struct {
    // è¾“å…¥æº
    source   []byte
    filename string
    
    // æ‰«æçŠ¶æ€
    offset   int      // å½“å‰å­—èŠ‚åç§»
    readOff  int      // ä¸‹ä¸€ä¸ªè¯»å–ä½ç½®
    lineNum  int      // å½“å‰è¡Œå·
    linePos  int      // è¡Œå†…ä½ç½®
    ch       rune     // å½“å‰å­—ç¬¦
    
    // é”™è¯¯
    errors   Errors
}

// newScanner: åˆ›å»ºscanner
func newScanner(source []byte) *scanner {
    s := &scanner{
        source:  source,
        lineNum: 1,
        linePos: 1,
    }
    s.next()  // è¯»å–ç¬¬ä¸€ä¸ªå­—ç¬¦
    return s
}
```

### 2.2 Tokenå®šä¹‰

**å®Œæ•´Tokenæšä¸¾**:

```go
const (
    // ç‰¹æ®Š
    ILLEGAL token = iota
    EOF
    COMMENT
    WHITESPACE
    
    literal_beg
    IDENT      // user
    NUMBER     // 123
    STRING     // "hello"
    RAWSTRING  // `raw`
    literal_end
    
    keyword_beg
    AS
    DEFAULT
    ELSE
    FALSE
    IF
    IMPORT
    NOT
    NULL
    PACKAGE
    TRUE
    WITH
    SOME
    keyword_end
    
    operator_beg
    ASSIGN     // :=
    EQ         // ==
    NEQ        // !=
    LT         // <
    LTE        // <=
    GT         // >
    GTE        // >=
    PLUS       // +
    MINUS      // -
    MUL        // *
    DIV        // /
    MOD        // %
    AND        // &
    OR         // |
    operator_end
    
    LPAREN     // (
    RPAREN     // )
    LBRACK     // [
    RBRACK     // ]
    LBRACE     // {
    RBRACE     // }
    COMMA      // ,
    DOT        // .
    SEMICOLON  // ;
    COLON      // :
)
```

### 2.3 è¯æ³•æ‰«æå®ç°

**æ ¸å¿ƒæ‰«æå‡½æ•°**:

```go
// scan: æ‰«æä¸‹ä¸€ä¸ªtoken
func (s *scanner) scan() (tok token, lit string, pos Pos) {
    // è·³è¿‡ç©ºç™½
    s.skipWhitespace()
    
    // è®°å½•ä½ç½®
    pos = s.position()
    
    // è¯»å–å½“å‰å­—ç¬¦
    ch := s.ch
    
    switch {
    case isLetter(ch):
        // æ ‡è¯†ç¬¦æˆ–å…³é”®å­—
        lit = s.scanIdentifier()
        tok = lookupKeyword(lit)
        return
        
    case isDigit(ch):
        // æ•°å­—
        tok, lit = s.scanNumber()
        return
        
    case ch == '"':
        // å­—ç¬¦ä¸²
        tok, lit = s.scanString()
        return
        
    case ch == '`':
        // åŸå§‹å­—ç¬¦ä¸²
        tok, lit = s.scanRawString()
        return
    }
    
    // è¿ç®—ç¬¦å’Œåˆ†éš”ç¬¦
    s.next()  // æ¶ˆè´¹å½“å‰å­—ç¬¦
    
    switch ch {
    case -1:
        tok = EOF
        
    case '(':
        tok = LPAREN
        
    case ')':
        tok = RPAREN
        
    case '[':
        tok = LBRACK
        
    case ']':
        tok = RBRACK
        
    case '{':
        tok = LBRACE
        
    case '}':
        tok = RBRACE
        
    case ',':
        tok = COMMA
        
    case '.':
        tok = DOT
        
    case ':':
        if s.ch == '=' {
            s.next()
            tok = ASSIGN  // :=
        } else {
            tok = COLON
        }
        
    case '=':
        if s.ch == '=' {
            s.next()
            tok = EQ  // ==
        } else {
            tok = ASSIGN
        }
        
    case '!':
        if s.ch == '=' {
            s.next()
            tok = NEQ  // !=
        } else {
            tok = NOT
        }
        
    case '<':
        if s.ch == '=' {
            s.next()
            tok = LTE  // <=
        } else {
            tok = LT
        }
        
    case '>':
        if s.ch == '=' {
            s.next()
            tok = GTE  // >=
        } else {
            tok = GT
        }
        
    case '+':
        tok = PLUS
        
    case '-':
        tok = MINUS
        
    case '*':
        tok = MUL
        
    case '/':
        tok = DIV
        
    case '%':
        tok = MOD
        
    case '#':
        // æ³¨é‡Š
        lit = s.scanComment()
        tok = COMMENT
        
    default:
        s.error("illegal character")
        tok = ILLEGAL
    }
    
    return
}
```

**è¾…åŠ©å‡½æ•°**:

```go
// next: è¯»å–ä¸‹ä¸€ä¸ªå­—ç¬¦
func (s *scanner) next() {
    if s.readOff < len(s.source) {
        s.offset = s.readOff
        if s.ch == '\n' {
            s.lineNum++
            s.linePos = 1
        } else {
            s.linePos++
        }
        r, w := rune(s.source[s.readOff]), 1
        if r >= utf8.RuneSelf {
            r, w = utf8.DecodeRune(s.source[s.readOff:])
        }
        s.readOff += w
        s.ch = r
    } else {
        s.offset = len(s.source)
        s.ch = -1  // EOF
    }
}

// skipWhitespace: è·³è¿‡ç©ºç™½å­—ç¬¦
func (s *scanner) skipWhitespace() {
    for s.ch == ' ' || s.ch == '\t' || s.ch == '\n' || s.ch == '\r' {
        s.next()
    }
}

// isLetter: åˆ¤æ–­æ˜¯å¦æ˜¯å­—æ¯
func isLetter(ch rune) bool {
    return 'a' <= ch && ch <= 'z' ||
           'A' <= ch && ch <= 'Z' ||
           ch == '_'
}

// isDigit: åˆ¤æ–­æ˜¯å¦æ˜¯æ•°å­—
func isDigit(ch rune) bool {
    return '0' <= ch && ch <= '9'
}
```

### 2.4 å…³é”®å­—è¯†åˆ«

**å…³é”®å­—æŸ¥æ‰¾è¡¨**:

```go
var keywords = map[string]token{
    "as":      AS,
    "default": DEFAULT,
    "else":    ELSE,
    "false":   FALSE,
    "if":      IF,
    "import":  IMPORT,
    "not":     NOT,
    "null":    NULL,
    "package": PACKAGE,
    "some":    SOME,
    "true":    TRUE,
    "with":    WITH,
}

// lookupKeyword: æŸ¥æ‰¾å…³é”®å­—
func lookupKeyword(ident string) token {
    if tok, ok := keywords[ident]; ok {
        return tok
    }
    return IDENT
}

// scanIdentifier: æ‰«ææ ‡è¯†ç¬¦
func (s *scanner) scanIdentifier() string {
    start := s.offset
    for isLetter(s.ch) || isDigit(s.ch) {
        s.next()
    }
    return string(s.source[start:s.offset])
}
```

### 2.5 å­—ç¬¦ä¸²ä¸è½¬ä¹‰

**å­—ç¬¦ä¸²æ‰«æ**:

```go
// scanString: æ‰«æåŒå¼•å·å­—ç¬¦ä¸²
func (s *scanner) scanString() (token, string) {
    // æ¶ˆè´¹å¼€å§‹çš„ "
    s.next()
    
    var buf bytes.Buffer
    start := s.offset
    
    for {
        ch := s.ch
        
        if ch == '\n' || ch < 0 {
            s.error("string literal not terminated")
            return ILLEGAL, ""
        }
        
        s.next()
        
        if ch == '"' {
            // å­—ç¬¦ä¸²ç»“æŸ
            break
        }
        
        if ch == '\\' {
            // è½¬ä¹‰åºåˆ—
            if buf.Len() == 0 {
                // ç¬¬ä¸€æ¬¡é‡åˆ°è½¬ä¹‰ï¼Œå…ˆå¤åˆ¶ä¹‹å‰çš„å†…å®¹
                buf.Write(s.source[start : s.offset-1])
            }
            
            ch = s.ch
            s.next()
            
            switch ch {
            case 'n':
                buf.WriteByte('\n')
            case 't':
                buf.WriteByte('\t')
            case 'r':
                buf.WriteByte('\r')
            case '"':
                buf.WriteByte('"')
            case '\\':
                buf.WriteByte('\\')
            case 'u':
                // Unicodeè½¬ä¹‰: \u1234
                r := s.scanUnicodeEscape(4)
                buf.WriteRune(r)
            case 'U':
                // Unicodeè½¬ä¹‰: \U12345678
                r := s.scanUnicodeEscape(8)
                buf.WriteRune(r)
            default:
                s.error("unknown escape sequence")
            }
        } else if buf.Len() > 0 {
            // å·²ç»æœ‰bufferäº†ï¼Œç»§ç»­è¿½åŠ 
            buf.WriteRune(ch)
        }
    }
    
    if buf.Len() > 0 {
        return STRING, buf.String()
    }
    return STRING, string(s.source[start : s.offset-1])
}

// scanUnicodeEscape: æ‰«æUnicodeè½¬ä¹‰
func (s *scanner) scanUnicodeEscape(length int) rune {
    var val rune
    for i := 0; i < length; i++ {
        ch := s.ch
        s.next()
        
        var d rune
        switch {
        case '0' <= ch && ch <= '9':
            d = ch - '0'
        case 'a' <= ch && ch <= 'f':
            d = ch - 'a' + 10
        case 'A' <= ch && ch <= 'F':
            d = ch - 'A' + 10
        default:
            s.error("illegal character in escape sequence")
            return 0
        }
        val = val*16 + d
    }
    return val
}

// scanRawString: æ‰«æåŸå§‹å­—ç¬¦ä¸²ï¼ˆåå¼•å·ï¼‰
func (s *scanner) scanRawString() (token, string) {
    // æ¶ˆè´¹å¼€å§‹çš„ `
    s.next()
    
    start := s.offset
    
    for {
        ch := s.ch
        
        if ch < 0 {
            s.error("raw string literal not terminated")
            return ILLEGAL, ""
        }
        
        s.next()
        
        if ch == '`' {
            break
        }
    }
    
    return RAWSTRING, string(s.source[start : s.offset-1])
}
```

### 2.6 æ•°å­—è§£æ

**æ•°å­—æ‰«æå®ç°**:

```go
// scanNumber: æ‰«ææ•°å­—
func (s *scanner) scanNumber() (token, string) {
    start := s.offset
    
    // å¤„ç†è´Ÿå·
    if s.ch == '-' {
        s.next()
    }
    
    // æ•´æ•°éƒ¨åˆ†
    s.scanDigits()
    
    tok := NUMBER
    
    // å°æ•°éƒ¨åˆ†
    if s.ch == '.' {
        s.next()
        s.scanDigits()
    }
    
    // æŒ‡æ•°éƒ¨åˆ†
    if s.ch == 'e' || s.ch == 'E' {
        s.next()
        if s.ch == '+' || s.ch == '-' {
            s.next()
        }
        s.scanDigits()
    }
    
    return tok, string(s.source[start:s.offset])
}

// scanDigits: æ‰«ææ•°å­—åºåˆ—
func (s *scanner) scanDigits() {
    for isDigit(s.ch) {
        s.next()
    }
}
```

---

## 3. è¯­æ³•è§£æå™¨ï¼ˆParserï¼‰

### 3.1 Parserç»“æ„

**Parserå®ç°**:

```go
// parser: è¯­æ³•è§£æå™¨
type parser struct {
    // è¯æ³•åˆ†æå™¨
    s *scanner
    
    // å½“å‰token
    tok    token
    tokVal string
    tokPos Pos
    
    // æ„å»ºä¸­çš„AST
    module *Module
    
    // é”™è¯¯å¤„ç†
    errors    Errors
    panicMode bool
    
    // ä¸Šä¸‹æ–‡
    inRule bool  // æ˜¯å¦åœ¨è§„åˆ™å†…éƒ¨
}

// newParser: åˆ›å»ºparser
func newParser(s *scanner) *parser {
    p := &parser{s: s}
    p.next()  // è¯»å–ç¬¬ä¸€ä¸ªtoken
    return p
}

// next: è·å–ä¸‹ä¸€ä¸ªtoken
func (p *parser) next() {
    p.tok, p.tokVal, p.tokPos = p.s.scan()
}

// expect: æœŸæœ›ç‰¹å®štoken
func (p *parser) expect(tok token) {
    if p.tok != tok {
        p.errorf("expected %s, got %s", tok, p.tok)
    }
    p.next()
}

// match: åŒ¹é…å¹¶æ¶ˆè´¹token
func (p *parser) match(tok token) bool {
    if p.tok == tok {
        p.next()
        return true
    }
    return false
}
```

### 3.2 é€’å½’ä¸‹é™è§£æ

**é€’å½’ä¸‹é™æ–¹æ³•**:

æ¯ä¸ªè¯­æ³•è§„åˆ™å¯¹åº”ä¸€ä¸ªè§£æå‡½æ•°ï¼š

```text
è¯­æ³•è§„åˆ™                 â†’  è§£æå‡½æ•°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Module                  â†’  parseModule()
Rule                    â†’  parseRule()
RuleHead                â†’  parseRuleHead()
RuleBody                â†’  parseRuleBody()
Expr                    â†’  parseExpr()
Term                    â†’  parseTerm()
```

**ç¤ºä¾‹è¯­æ³•è§„åˆ™**:

```text
Module    = Package Imports* Rules*
Rule      = RuleHead RuleBody?
RuleHead  = Ref (ASSIGN | LPAREN)? Term*
RuleBody  = IF Body
Body      = Expr (SEMICOLON Expr)*
Expr      = Term | Expr OP Expr | NOT Expr
Term      = Ref | Var | Scalar | Array | Object | Set | Comprehension
```

### 3.3 æ¨¡å—è§£æ

**parseModuleå®ç°**:

```go
// parseModule: è§£æRegoæ¨¡å—
func (p *parser) parseModule() *Module {
    module := &Module{
        Location: p.tokPos.Location,
    }
    p.module = module
    
    // 1. è§£æ package å£°æ˜
    module.Package = p.parsePackage()
    
    // 2. è§£æ import è¯­å¥
    for p.tok == IMPORT {
        imp := p.parseImport()
        module.Imports = append(module.Imports, imp)
    }
    
    // 3. è§£æè§„åˆ™
    for p.tok != EOF {
        if rule := p.parseRule(); rule != nil {
            module.Rules = append(module.Rules, rule)
        }
    }
    
    return module
}

// parsePackage: è§£æpackageå£°æ˜
func (p *parser) parsePackage() *Package {
    // package <ref>
    p.expect(PACKAGE)
    
    pkg := &Package{
        Location: p.tokPos.Location,
        Path:     p.parseRef(),
    }
    
    return pkg
}

// parseImport: è§£æimportè¯­å¥
func (p *parser) parseImport() *Import {
    // import <ref> [as <var>]
    p.expect(IMPORT)
    
    imp := &Import{
        Location: p.tokPos.Location,
        Path:     p.parseRef(),
    }
    
    if p.match(AS) {
        imp.Alias = p.parseVar()
    }
    
    return imp
}
```

### 3.4 è§„åˆ™è§£æ

**parseRuleå®ç°**:

```go
// parseRule: è§£æè§„åˆ™
func (p *parser) parseRule() *Rule {
    rule := &Rule{
        Location: p.tokPos.Location,
    }
    
    // 1. è§£æ default å…³é”®å­—
    if p.match(DEFAULT) {
        rule.Default = true
    }
    
    // 2. è§£æè§„åˆ™å¤´éƒ¨
    rule.Head = p.parseRuleHead()
    
    // 3. è§£æè§„åˆ™ä½“ï¼ˆå¯é€‰ï¼‰
    if p.tok == IF || p.tok == LBRACE {
        rule.Body = p.parseRuleBody()
    }
    
    return rule
}

// parseRuleHead: è§£æè§„åˆ™å¤´éƒ¨
func (p *parser) parseRuleHead() *Head {
    head := &Head{
        Location: p.tokPos.Location,
    }
    
    // è§„åˆ™åç§°ï¼ˆå¯èƒ½æ˜¯å¼•ç”¨ï¼‰
    head.Name = p.parseRef()
    
    // å‡½æ•°å‚æ•°
    if p.match(LPAREN) {
        head.Args = p.parseTermList()
        p.expect(RPAREN)
    }
    
    // èµ‹å€¼æˆ–ç»Ÿä¸€
    if p.match(ASSIGN) {
        // head := value
        head.Value = p.parseTerm()
    } else if p.match(EQ) {
        // head = value (ç­‰å¼)
        head.Value = p.parseTerm()
        head.Assign = false
    }
    
    return head
}

// parseRuleBody: è§£æè§„åˆ™ä½“
func (p *parser) parseRuleBody() Body {
    var body Body
    
    // å¯é€‰çš„ if å…³é”®å­— (Rego v1.0)
    p.match(IF)
    
    // è§£æè¡¨è¾¾å¼åˆ—è¡¨
    if p.match(LBRACE) {
        // å¤šè¡Œè§„åˆ™ä½“: { expr1; expr2; ... }
        for p.tok != RBRACE && p.tok != EOF {
            expr := p.parseExpr()
            body = append(body, expr)
            
            // è¡¨è¾¾å¼åˆ†éš”ç¬¦ï¼ˆåˆ†å·æˆ–æ¢è¡Œï¼‰
            if !p.match(SEMICOLON) && p.tok != RBRACE {
                p.match(WHITESPACE)
            }
        }
        p.expect(RBRACE)
    } else {
        // å•è¡Œè§„åˆ™ä½“: expr1; expr2
        for {
            expr := p.parseExpr()
            body = append(body, expr)
            
            if !p.match(SEMICOLON) {
                break
            }
        }
    }
    
    return body
}
```

### 3.5 è¡¨è¾¾å¼è§£æ

**parseExprå®ç°**:

```go
// parseExpr: è§£æè¡¨è¾¾å¼
func (p *parser) parseExpr() *Expr {
    return p.parseInfixExpr(0)
}

// parseInfixExpr: è§£æä¸­ç¼€è¡¨è¾¾å¼ï¼ˆè¿ç®—ç¬¦ä¼˜å…ˆçº§ï¼‰
func (p *parser) parseInfixExpr(minPrec int) *Expr {
    // è§£æå·¦ä¾§
    left := p.parseUnaryExpr()
    
    // å¾ªç¯å¤„ç†ä¸­ç¼€è¿ç®—ç¬¦
    for {
        op := p.tok
        prec := precedence(op)
        
        if prec < minPrec {
            break
        }
        
        p.next()
        
        // è§£æå³ä¾§ï¼ˆé€’å½’ï¼Œå¤„ç†ç»“åˆæ€§ï¼‰
        right := p.parseInfixExpr(prec + 1)
        
        // æ„å»ºè¡¨è¾¾å¼
        left = &Expr{
            Location: left.Location,
            Terms: []*Term{
                &Term{Value: Ref{Var(op.String())}},  // è¿ç®—ç¬¦
                &Term{Value: left},                     // å·¦æ“ä½œæ•°
                &Term{Value: right},                    // å³æ“ä½œæ•°
            },
        }
    }
    
    return left
}

// parseUnaryExpr: è§£æä¸€å…ƒè¡¨è¾¾å¼
func (p *parser) parseUnaryExpr() *Expr {
    switch p.tok {
    case NOT:
        // not expr
        p.next()
        expr := p.parseUnaryExpr()
        return &Expr{
            Negated: true,
            Terms:   expr.Terms,
        }
        
    case SOME:
        // some var in collection
        return p.parseSomeDecl()
        
    default:
        // æ™®é€šè¡¨è¾¾å¼
        return p.parsePrimaryExpr()
    }
}

// parsePrimaryExpr: è§£æåŸºæœ¬è¡¨è¾¾å¼
func (p *parser) parsePrimaryExpr() *Expr {
    // è¡¨è¾¾å¼ = é¡¹ | é¡¹ è¿ç®—ç¬¦ é¡¹
    left := p.parseTerm()
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯äºŒå…ƒè¿ç®—ç¬¦
    if isBinaryOp(p.tok) {
        return p.parseBinaryExpr(left)
    }
    
    // å•é¡¹è¡¨è¾¾å¼
    return &Expr{
        Location: left.Location,
        Terms:    []*Term{left},
    }
}
```

### 3.6 é¡¹ï¼ˆTermï¼‰è§£æ

**parseTermå®ç°**:

```go
// parseTerm: è§£æé¡¹
func (p *parser) parseTerm() *Term {
    term := &Term{
        Location: p.tokPos.Location,
    }
    
    switch p.tok {
    case IDENT:
        // å˜é‡æˆ–å¼•ç”¨
        term.Value = p.parseRefOrVar()
        
    case NULL:
        p.next()
        term.Value = Null{}
        
    case TRUE:
        p.next()
        term.Value = Boolean(true)
        
    case FALSE:
        p.next()
        term.Value = Boolean(false)
        
    case NUMBER:
        term.Value = p.parseNumber()
        
    case STRING, RAWSTRING:
        term.Value = p.parseString()
        
    case LBRACK:
        // æ•°ç»„: [1, 2, 3] æˆ– æ¨å¯¼å¼: [x | ...]
        term.Value = p.parseArrayOrComprehension()
        
    case LBRACE:
        // å¯¹è±¡: {a: 1} æˆ– é›†åˆ: {1, 2} æˆ– æ¨å¯¼å¼
        term.Value = p.parseObjectOrSetOrComprehension()
        
    case LPAREN:
        // æ‹¬å·è¡¨è¾¾å¼
        p.next()
        inner := p.parseTerm()
        p.expect(RPAREN)
        return inner
        
    default:
        p.errorf("unexpected token in term: %s", p.tok)
        p.next()
    }
    
    return term
}

// parseRefOrVar: è§£æå¼•ç”¨æˆ–å˜é‡
func (p *parser) parseRefOrVar() Value {
    // å¼€å§‹æ˜¯æ ‡è¯†ç¬¦
    name := p.tokVal
    p.next()
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯å¼•ç”¨ï¼ˆæœ‰.æˆ–[ï¼‰
    if p.tok == DOT || p.tok == LBRACK {
        ref := Ref{Var(name)}
        return p.parseRefSuffix(ref)
    }
    
    // å•çº¯çš„å˜é‡
    return Var(name)
}

// parseRefSuffix: è§£æå¼•ç”¨åç¼€
func (p *parser) parseRefSuffix(ref Ref) Ref {
    for {
        switch p.tok {
        case DOT:
            // .field
            p.next()
            if p.tok != IDENT {
                p.errorf("expected identifier after .")
                return ref
            }
            ref = append(ref, StringTerm(p.tokVal))
            p.next()
            
        case LBRACK:
            // [index] æˆ– [key]
            p.next()
            index := p.parseTerm()
            ref = append(ref, index)
            p.expect(RBRACK)
            
        default:
            return ref
        }
    }
}
```

---

## 4. è¿ç®—ç¬¦ä¼˜å…ˆçº§

### 4.1 ä¼˜å…ˆçº§è¡¨

**è¿ç®—ç¬¦ä¼˜å…ˆçº§**ï¼ˆä»ä½åˆ°é«˜ï¼‰:

```go
const (
    PREC_LOWEST      = iota
    PREC_ASSIGNMENT  // :=
    PREC_OR          // |
    PREC_AND         // &
    PREC_NOT         // not
    PREC_COMPARE     // ==, !=, <, <=, >, >=
    PREC_ADD         // +, -
    PREC_MUL         // *, /, %
    PREC_UNARY       // -x, not x
    PREC_CALL        // f(x)
    PREC_INDEX       // x[i], x.field
)

// precedence: è·å–è¿ç®—ç¬¦ä¼˜å…ˆçº§
func precedence(tok token) int {
    switch tok {
    case ASSIGN:
        return PREC_ASSIGNMENT
    case OR:
        return PREC_OR
    case AND:
        return PREC_AND
    case EQ, NEQ, LT, LTE, GT, GTE:
        return PREC_COMPARE
    case PLUS, MINUS:
        return PREC_ADD
    case MUL, DIV, MOD:
        return PREC_MUL
    }
    return PREC_LOWEST
}
```

### 4.2 è¡¨è¾¾å¼è§£æç®—æ³•

**Precedence Climbingç®—æ³•**:

```go
// parseInfixExpr: ä¼˜å…ˆçº§çˆ¬å‡ç®—æ³•
func (p *parser) parseInfixExpr(minPrec int) *Expr {
    // è§£æå·¦æ“ä½œæ•°
    left := p.parsePrimary()
    
    for {
        // æŸ¥çœ‹å½“å‰è¿ç®—ç¬¦
        op := p.tok
        prec := precedence(op)
        
        // ä¼˜å…ˆçº§ä¸å¤Ÿï¼Œè¿”å›
        if prec < minPrec {
            break
        }
        
        p.next()  // æ¶ˆè´¹è¿ç®—ç¬¦
        
        // é€’å½’è§£æå³æ“ä½œæ•°
        // prec + 1 ä¿è¯å·¦ç»“åˆ
        right := p.parseInfixExpr(prec + 1)
        
        // æ„å»ºæ–°çš„è¡¨è¾¾å¼
        left = makeBinaryExpr(op, left, right)
    }
    
    return left
}
```

**ç¤ºä¾‹**:

```text
è¾“å…¥: a + b * c - d

è§£æè¿‡ç¨‹:
1. parseInfixExpr(0)
   - left = a
   - çœ‹åˆ° +, prec=2 >= 0, æ¶ˆè´¹
   - right = parseInfixExpr(3)
     - left = b
     - çœ‹åˆ° *, prec=3 >= 3, æ¶ˆè´¹
     - right = parseInfixExpr(4)
       - left = c
       - çœ‹åˆ° -, prec=2 < 4, è¿”å› c
     - æ„å»º b * c
     - çœ‹åˆ° -, prec=2 < 3, è¿”å› b*c
   - æ„å»º a + (b*c)
   - çœ‹åˆ° -, prec=2 >= 0, æ¶ˆè´¹
   - right = parseInfixExpr(3)
     - left = d
     - çœ‹åˆ° EOF, è¿”å› d
   - æ„å»º (a + (b*c)) - d

ç»“æœAST:
      -
     / \
    +   d
   / \
  a   *
     / \
    b   c
```

### 4.3 Pratt Parsing

OPAçš„è¡¨è¾¾å¼è§£æå™¨å€Ÿé‰´äº†**Pratt Parsing**æ€æƒ³ï¼š

```go
// Pratt Parseræ ¸å¿ƒæ€æƒ³
type prefixParseFn func() *Expr
type infixParseFn func(*Expr) *Expr

type parser struct {
    prefixFns map[token]prefixParseFn
    infixFns  map[token]infixParseFn
}

// æ³¨å†Œå‰ç¼€è§£æå‡½æ•°
func (p *parser) registerPrefix(tok token, fn prefixParseFn) {
    p.prefixFns[tok] = fn
}

// æ³¨å†Œä¸­ç¼€è§£æå‡½æ•°
func (p *parser) registerInfix(tok token, fn infixParseFn) {
    p.infixFns[tok] = fn
}
```

---

## 5. é”™è¯¯å¤„ç†

### 5.1 é”™è¯¯ç±»å‹

**é”™è¯¯å®šä¹‰**:

```go
// Error: è§£æé”™è¯¯
type Error struct {
    Location *Location  // é”™è¯¯ä½ç½®
    Message  string     // é”™è¯¯ä¿¡æ¯
    Code     string     // é”™è¯¯ä»£ç 
}

// Errors: é”™è¯¯åˆ—è¡¨
type Errors []Error

// å¸¸è§é”™è¯¯ä»£ç 
const (
    ParseErr        = "rego_parse_error"
    CompileErr      = "rego_compile_error"
    TypeError       = "rego_type_error"
    UnsafeVarErr    = "rego_unsafe_var_error"
)

// errorf: åˆ›å»ºé”™è¯¯
func (p *parser) errorf(format string, args ...interface{}) {
    err := Error{
        Location: p.tokPos.Location,
        Message:  fmt.Sprintf(format, args...),
        Code:     ParseErr,
    }
    p.errors = append(p.errors, err)
}
```

### 5.2 é”™è¯¯æ¢å¤ç­–ç•¥

**Panic Modeæ¢å¤**:

```go
// recover: é”™è¯¯æ¢å¤
func (p *parser) recover() {
    p.panicMode = true
    
    // è·³è¿‡tokenç›´åˆ°æ‰¾åˆ°åŒæ­¥ç‚¹
    for !p.atSyncPoint() && p.tok != EOF {
        p.next()
    }
    
    p.panicMode = false
}

// atSyncPoint: æ˜¯å¦åœ¨åŒæ­¥ç‚¹
func (p *parser) atSyncPoint() bool {
    switch p.tok {
    case PACKAGE, IMPORT, DEFAULT:
        return true
    case RBRACE:
        return !p.inRule
    }
    return false
}

// parseRule with recovery
func (p *parser) parseRule() *Rule {
    defer func() {
        if r := recover(); r != nil {
            p.recover()
        }
    }()
    
    rule := &Rule{}
    
    // ... è§£æé€»è¾‘ ...
    
    return rule
}
```

### 5.3 é”™è¯¯æŠ¥å‘Š

**å‹å¥½çš„é”™è¯¯ä¿¡æ¯**:

```go
// formatError: æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
func formatError(err Error, source []byte) string {
    var buf bytes.Buffer
    
    // é”™è¯¯å¤´éƒ¨
    fmt.Fprintf(&buf, "%s:%d:%d: %s\n",
        err.Location.File,
        err.Location.Row,
        err.Location.Col,
        err.Message)
    
    // æ˜¾ç¤ºæºä»£ç è¡Œ
    line := getLine(source, err.Location.Row)
    fmt.Fprintf(&buf, "%s\n", line)
    
    // æ˜¾ç¤ºé”™è¯¯ä½ç½®æ ‡è®°
    fmt.Fprintf(&buf, "%s^\n", strings.Repeat(" ", err.Location.Col-1))
    
    return buf.String()
}

// ç¤ºä¾‹è¾“å‡º:
// policy.rego:5:12: expected ), got IDENT
// allow if user = "admin"
//            ^
```

### 5.4 ä½ç½®è¿½è¸ª

**ä½ç½®ä¿¡æ¯**:

```go
// Location: æºç ä½ç½®
type Location struct {
    File   string  // æ–‡ä»¶å
    Row    int     // è¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰
    Col    int     // åˆ—å·ï¼ˆä»1å¼€å§‹ï¼‰
    Offset int     // å­—èŠ‚åç§»
}

// Pos: ä½ç½®ä¿¡æ¯
type Pos struct {
    Location *Location
}

// position: è·å–å½“å‰ä½ç½®
func (s *scanner) position() Pos {
    return Pos{
        Location: &Location{
            File:   s.filename,
            Row:    s.lineNum,
            Col:    s.linePos,
            Offset: s.offset,
        },
    }
}

// åœ¨ASTèŠ‚ç‚¹ä¸­ä¿å­˜ä½ç½®
type Rule struct {
    Location *Location  // è§„åˆ™å®šä¹‰ä½ç½®
    Head     *Head
    Body     Body
}
```

---

## 6. ç‰¹æ®Šè¯­æ³•å¤„ç†

### 6.1 é›†åˆæ¨å¯¼å¼

**è¯­æ³•**: `{ x | x = arr[_]; x > 5 }`

**è§£æå®ç°**:

```go
// parseSetComprehension: è§£æé›†åˆæ¨å¯¼å¼
func (p *parser) parseSetComprehension() *SetComprehension {
    // { term | body }
    p.expect(LBRACE)
    
    comp := &SetComprehension{
        Location: p.tokPos.Location,
    }
    
    // è§£æé¡¹ï¼ˆç»“æœè¡¨è¾¾å¼ï¼‰
    comp.Term = p.parseTerm()
    
    // æœŸæœ› |
    p.expect(OR)
    
    // è§£ææ¨å¯¼ä½“
    comp.Body = p.parseBody()
    
    p.expect(RBRACE)
    
    return comp
}

// ASTè¡¨ç¤º:
// SetComprehension {
//     Term: Var("x"),
//     Body: [
//         Expr(x = arr[_]),
//         Expr(x > 5),
//     ]
// }
```

### 6.2 å¯¹è±¡æ¨å¯¼å¼

**è¯­æ³•**: `{ k: v | k = keys[_]; v = values[k] }`

**è§£æå®ç°**:

```go
// parseObjectComprehension: è§£æå¯¹è±¡æ¨å¯¼å¼
func (p *parser) parseObjectComprehension() *ObjectComprehension {
    // { key: value | body }
    p.expect(LBRACE)
    
    comp := &ObjectComprehension{
        Location: p.tokPos.Location,
    }
    
    // è§£æé”®
    comp.Key = p.parseTerm()
    
    p.expect(COLON)
    
    // è§£æå€¼
    comp.Value = p.parseTerm()
    
    p.expect(OR)
    
    // è§£ææ¨å¯¼ä½“
    comp.Body = p.parseBody()
    
    p.expect(RBRACE)
    
    return comp
}
```

### 6.3 æ•°ç»„æ¨å¯¼å¼

**è¯­æ³•**: `[ x | x = arr[_]; x > 5 ]`

**è§£æå®ç°**:

```go
// parseArrayComprehension: è§£ææ•°ç»„æ¨å¯¼å¼
func (p *parser) parseArrayComprehension() *ArrayComprehension {
    // [ term | body ]
    p.expect(LBRACK)
    
    comp := &ArrayComprehension{
        Location: p.tokPos.Location,
    }
    
    // è§£æé¡¹
    comp.Term = p.parseTerm()
    
    p.expect(OR)
    
    // è§£ææ¨å¯¼ä½“
    comp.Body = p.parseBody()
    
    p.expect(RBRACK)
    
    return comp
}
```

### 6.4 å¼•ç”¨ï¼ˆReferenceï¼‰

**è¯­æ³•**: `data.users[0].name`

**è§£æå®ç°**:

```go
// parseRef: è§£æå¼•ç”¨
func (p *parser) parseRef() Ref {
    ref := Ref{}
    
    // ç¬¬ä¸€éƒ¨åˆ†ï¼šå¿…é¡»æ˜¯æ ‡è¯†ç¬¦
    if p.tok != IDENT {
        p.errorf("expected identifier")
        return ref
    }
    
    ref = append(ref, VarTerm(p.tokVal))
    p.next()
    
    // åç»­éƒ¨åˆ†ï¼š.field æˆ– [index]
    for {
        switch p.tok {
        case DOT:
            // .field
            p.next()
            if p.tok != IDENT {
                p.errorf("expected identifier after .")
                return ref
            }
            ref = append(ref, StringTerm(p.tokVal))
            p.next()
            
        case LBRACK:
            // [index]
            p.next()
            
            // ç‰¹æ®Šå¤„ç† [_] (é€šé…ç¬¦)
            if p.tok == IDENT && p.tokVal == "_" {
                ref = append(ref, VarTerm("$_"))
                p.next()
            } else {
                index := p.parseTerm()
                ref = append(ref, index)
            }
            
            p.expect(RBRACK)
            
        default:
            return ref
        }
    }
}

// ç¤ºä¾‹AST:
// data.users[0].name â†’
// Ref[
//     Var("data"),
//     String("users"),
//     Number(0),
//     String("name"),
// ]
```

### 6.5 å‡½æ•°è°ƒç”¨

**è¯­æ³•**: `count(arr)`, `startswith(str, prefix)`

**è§£æå®ç°**:

```go
// parseFunctionCall: è§£æå‡½æ•°è°ƒç”¨
func (p *parser) parseFunctionCall(name *Term) *Term {
    // name(arg1, arg2, ...)
    
    call := &Call{
        Location: name.Location,
        Func:     name,
        Args:     []*Term{},
    }
    
    p.expect(LPAREN)
    
    // è§£æå‚æ•°åˆ—è¡¨
    if p.tok != RPAREN {
        for {
            arg := p.parseTerm()
            call.Args = append(call.Args, arg)
            
            if !p.match(COMMA) {
                break
            }
        }
    }
    
    p.expect(RPAREN)
    
    return &Term{
        Location: name.Location,
        Value:    call,
    }
}

// åœ¨parseTermä¸­æ£€æµ‹å‡½æ•°è°ƒç”¨:
func (p *parser) parseTerm() *Term {
    term := p.parseBasicTerm()
    
    // æ£€æŸ¥æ˜¯å¦æ˜¯å‡½æ•°è°ƒç”¨
    if p.tok == LPAREN {
        return p.parseFunctionCall(term)
    }
    
    return term
}
```

---

## 7. æºç å®ç°åˆ†æ

### 7.1 Scanneræ ¸å¿ƒä»£ç 

**å®é™…OPA Scannerä»£ç ç‰‡æ®µ**:

```go
// æ¥è‡ª: ast/parser.go

// scannerå®ç°
type scanner struct {
    reader *bytes.Reader
    buffer []byte
    
    // ä½ç½®
    offset int
    row    int
    col    int
    
    // å½“å‰å­—ç¬¦
    ch rune
}

// scanæ–¹æ³•ï¼ˆç®€åŒ–ç‰ˆï¼‰
func (s *scanner) scan() (token, string, Pos) {
    s.skipWhitespace()
    
    pos := s.pos()
    ch := s.ch
    
    switch {
    case isLetter(ch):
        lit := s.scanIdentifier()
        tok := lookupKeyword(lit)
        return tok, lit, pos
        
    case isDigit(ch) || ch == '-' && isDigit(s.peek()):
        return s.scanNumber()
        
    case ch == '"':
        return s.scanString()
        
    case ch == '#':
        s.scanComment()
        return s.scan()  // é€’å½’è·³è¿‡æ³¨é‡Š
    }
    
    // è¿ç®—ç¬¦å’Œæ ‡ç‚¹
    s.next()
    
    switch ch {
    case ':':
        if s.ch == '=' {
            s.next()
            return ASSIGN, ":=", pos
        }
        return COLON, ":", pos
        
    case '=':
        if s.ch == '=' {
            s.next()
            return EQ, "==", pos
        }
        return ILLEGAL, "=", pos
        
    // ... å…¶ä»–è¿ç®—ç¬¦ ...
    }
    
    return ILLEGAL, string(ch), pos
}
```

### 7.2 Parseræ ¸å¿ƒä»£ç 

**å®é™…OPA Parserä»£ç ç‰‡æ®µ**:

```go
// æ¥è‡ª: ast/parser.go

// parseModuleå®ç°
func (p *parser) parseModule(filename string) (*Module, error) {
    module := &Module{}
    
    // Packageå£°æ˜
    if p.tok == PACKAGE {
        module.Package = p.parsePackage()
    }
    
    // Importè¯­å¥
    for p.tok == IMPORT {
        module.Imports = append(module.Imports, p.parseImport())
    }
    
    // è§„åˆ™
    for p.tok != EOF {
        if stmt := p.parseStmt(); stmt != nil {
            module.Rules = append(module.Rules, stmt)
        }
    }
    
    return module, nil
}

// parseStmt: è§£æè¯­å¥ï¼ˆè§„åˆ™æˆ–æ³¨é‡Šï¼‰
func (p *parser) parseStmt() interface{} {
    switch p.tok {
    case DEFAULT:
        return p.parseRule(true)
    case COMMENT:
        c := p.parseComment()
        p.next()
        return c
    default:
        return p.parseRule(false)
    }
}

// parseRuleçš„çœŸå®å®ç°ï¼ˆç®€åŒ–ï¼‰
func (p *parser) parseRule(isDefault bool) *Rule {
    rule := &Rule{
        Default: isDefault,
    }
    
    // è§„åˆ™å¤´éƒ¨
    rule.Head = p.parseHead()
    
    // è§„åˆ™ä½“ï¼ˆå¯é€‰ï¼‰
    if p.tok == IF || p.tok == LBRACE {
        p.match(IF)  // Rego v1.0è¯­æ³•
        rule.Body = p.parseBody()
    } else {
        rule.Body = NewBody()
    }
    
    return rule
}
```

### 7.3 æ€§èƒ½ä¼˜åŒ–

**OPAè§£æå™¨çš„æ€§èƒ½ä¼˜åŒ–**:

1. **é›¶æ‹·è´å­—ç¬¦ä¸²**:

    ```go
    // ä½¿ç”¨byte sliceè§†å›¾ï¼Œé¿å…å†…å­˜æ‹·è´
    func (s *scanner) scanIdentifier() string {
        start := s.offset
        s.scanIdentChars()
        // ç›´æ¥è¿”å›åº•å±‚bufferçš„å­—ç¬¦ä¸²è§†å›¾
        return string(s.buffer[start:s.offset])
    }
    ```

2. **é¢„åˆ†é…ç¼“å†²åŒº**:

    ```go
    // é¢„åˆ†é…å¸¸è§å¤§å°çš„slice
    func parseBody() Body {
        body := make(Body, 0, 8)  // å¤§å¤šæ•°è§„åˆ™ä½“ < 8ä¸ªè¡¨è¾¾å¼
        // ...
        return body
    }
    ```

3. **å…³é”®å­—æŸ¥æ‰¾è¡¨**:

    ```go
    // ä½¿ç”¨mapè€Œä¸æ˜¯if-elseé“¾
    var keywords = map[string]token{
        "package": PACKAGE,
        "import":  IMPORT,
        // ...
    }
    ```

4. **æƒ°æ€§ASTæ„å»º**:

    ```go
    // åªåœ¨éœ€è¦æ—¶æ„å»ºå®Œæ•´AST
    type LazyRule struct {
        raw    []byte
        parsed *Rule
    }

    func (r *LazyRule) Parse() *Rule {
        if r.parsed == nil {
            r.parsed = parseRule(r.raw)
        }
        return r.parsed
    }
    ```

---

## 8. å®æˆ˜ç¤ºä¾‹

### 8.1 ç®€å•è§„åˆ™è§£æ

**è¾“å…¥Rego**:

```rego
package example

allow if {
    input.method == "GET"
    input.user.role == "admin"
}
```

**è§£æè¿‡ç¨‹**:

```go
// 1. è¯æ³•åˆ†æ
tokens := [
    PACKAGE, IDENT("example"),
    IDENT("allow"), IF, LBRACE,
    IDENT("input"), DOT, IDENT("method"), EQ, EQ, STRING("GET"),
    IDENT("input"), DOT, IDENT("user"), DOT, IDENT("role"), EQ, EQ, STRING("admin"),
    RBRACE,
    EOF,
]

// 2. è¯­æ³•åˆ†æ
module := &Module{
    Package: &Package{
        Path: Ref{Var("example")},
    },
    Rules: []*Rule{
        {
            Head: &Head{
                Name: Ref{Var("allow")},
            },
            Body: Body{
                &Expr{
                    Terms: []*Term{
                        &Term{Value: Ref{Var("input"), String("method")}},
                        &Term{Value: String("GET")},
                    },
                    Operator: EQ,
                },
                &Expr{
                    Terms: []*Term{
                        &Term{Value: Ref{Var("input"), String("user"), String("role")}},
                        &Term{Value: String("admin")},
                    },
                    Operator: EQ,
                },
            },
        },
    },
}
```

### 8.2 å¤æ‚è¡¨è¾¾å¼è§£æ

**è¾“å…¥Rego**:

```rego
result := (a + b) * c - d / e
```

**è¿ç®—ç¬¦ä¼˜å…ˆçº§è§£æ**:

```text
Tokenæµ: result ASSIGN LPAREN a PLUS b RPAREN MUL c MINUS d DIV e

è§£æè¿‡ç¨‹:
1. result := ...
   - parseRule()
   - parseHead()
     - name = "result"
     - ASSIGN
     - value = parseExpr()

2. parseExpr() with minPrec=0
   - left = parsePrimary()
     - LPAREN
     - inner = (a + b)  # é€’å½’
     - RPAREN
   
   - çœ‹åˆ° MUL, prec=3 >= 0
   - right = parseExpr(4)
     - left = c
     - çœ‹åˆ° MINUS, prec=2 < 4, è¿”å› c
   - æ„å»º: (a+b) * c
   
   - çœ‹åˆ° MINUS, prec=2 >= 0
   - right = parseExpr(3)
     - left = d
     - çœ‹åˆ° DIV, prec=3 >= 3
     - right = parseExpr(4)
       - left = e
       - EOF
     - æ„å»º: d / e
   - æ„å»º: ((a+b)*c) - (d/e)

æœ€ç»ˆAST:
        ASSIGN
       /      \
    result    MINUS
              /     \
            MUL     DIV
           /   \   /   \
         PLUS  c  d     e
        /    \
       a      b
```

### 8.3 é”™è¯¯å¤„ç†ç¤ºä¾‹

**è¾“å…¥ï¼ˆæœ‰é”™è¯¯ï¼‰**:

```rego
package example

allow if {
    input.method == GET"   # ç¼ºå°‘åŒå¼•å·
    input.user.role = "admin"  # åº”è¯¥æ˜¯ ==
}
```

**é”™è¯¯æŠ¥å‘Š**:

```text
example.rego:4:21: expected STRING, got IDENT
    input.method == GET"
                    ^

example.rego:5:21: illegal token '='
    input.user.role = "admin"
                    ^

Parsed with 2 errors
```

---

## 9. æµ‹è¯•ä¸éªŒè¯

### 9.1 å•å…ƒæµ‹è¯•

**æµ‹è¯•Scanner**:

```go
func TestScanner(t *testing.T) {
    tests := []struct {
        input    string
        expected []token
    }{
        {
            input: "package example",
            expected: []token{PACKAGE, IDENT, EOF},
        },
        {
            input: "x := 10",
            expected: []token{IDENT, ASSIGN, NUMBER, EOF},
        },
        {
            input: `"hello \"world\""`,
            expected: []token{STRING, EOF},
        },
    }
    
    for _, tt := range tests {
        s := newScanner([]byte(tt.input))
        
        for i, exp := range tt.expected {
            tok, _, _ := s.scan()
            if tok != exp {
                t.Errorf("test %d: expected %s, got %s", i, exp, tok)
            }
        }
    }
}
```

**æµ‹è¯•Parser**:

```go
func TestParser(t *testing.T) {
    input := `
package example

allow if {
    input.method == "GET"
}
`
    
    module, err := ParseModule("test.rego", []byte(input))
    if err != nil {
        t.Fatal(err)
    }
    
    // éªŒè¯ASTç»“æ„
    if module.Package.Path.String() != "data.example" {
        t.Errorf("wrong package path")
    }
    
    if len(module.Rules) != 1 {
        t.Errorf("expected 1 rule, got %d", len(module.Rules))
    }
    
    rule := module.Rules[0]
    if rule.Head.Name.String() != "allow" {
        t.Errorf("wrong rule name")
    }
    
    if len(rule.Body) != 1 {
        t.Errorf("expected 1 expression in body")
    }
}
```

### 9.2 æ€§èƒ½æµ‹è¯•

**Benchmark**:

```go
func BenchmarkParser(b *testing.B) {
    input := []byte(`
package example

allow if {
    input.method == "GET"
    input.path == "/api"
    input.user.role == "admin"
}
`)
    
    b.ResetTimer()
    for i := 0; i < b.N; i++ {
        _, err := ParseModule("test.rego", input)
        if err != nil {
            b.Fatal(err)
        }
    }
}

// ç»“æœç¤ºä¾‹:
// BenchmarkParser-8    50000    25000 ns/op    8192 B/op    150 allocs/op
```

### 9.3 Fuzzingæµ‹è¯•

**Fuzzæµ‹è¯•**:

```go
func FuzzParser(f *testing.F) {
    // æ·»åŠ ç§å­è¯­æ–™
    f.Add([]byte("package example"))
    f.Add([]byte("allow if { true }"))
    
    f.Fuzz(func(t *testing.T, data []byte) {
        // è§£æä¸åº”è¯¥panic
        _, _ = ParseModule("fuzz.rego", data)
    })
}

// è¿è¡Œ: go test -fuzz=FuzzParser
```

---

## é™„å½•

### A. Tokenå®Œæ•´åˆ—è¡¨

**æ‰€æœ‰Tokenç±»å‹**:

```go
const (
    // ç‰¹æ®Š
    ILLEGAL token = iota
    EOF
    COMMENT
    
    // å­—é¢é‡
    IDENT
    NUMBER
    STRING
    RAWSTRING
    
    // å…³é”®å­—
    AS
    DEFAULT
    ELSE
    FALSE
    IF
    IMPORT
    IN
    NOT
    NULL
    PACKAGE
    SOME
    TRUE
    WITH
    EVERY
    CONTAINS
    
    // è¿ç®—ç¬¦
    ASSIGN     // :=
    EQ         // ==
    NEQ        // !=
    LT         // <
    LTE        // <=
    GT         // >
    GTE        // >=
    PLUS       // +
    MINUS      // -
    MUL        // *
    DIV        // /
    MOD        // %
    AND        // &
    OR         // |
    
    // åˆ†éš”ç¬¦
    LPAREN     // (
    RPAREN     // )
    LBRACK     // [
    RBRACK     // ]
    LBRACE     // {
    RBRACE     // }
    COMMA      // ,
    DOT        // .
    SEMICOLON  // ;
    COLON      // :
    PIPE       // |
)
```

### B. è¯­æ³•è§„åˆ™BNF

**Regoè¯­æ³•BNF**:

```bnf
Module        ::= Package Imports* Rules*
Package       ::= "package" Ref
Import        ::= "import" Ref ("as" Var)?

Rule          ::= "default"? RuleHead RuleBody?
RuleHead      ::= Ref ("(" TermList? ")")? (":=" | "=")? Term
RuleBody      ::= "if"? Body

Body          ::= "{" Expr* "}" | Expr
Expr          ::= Term
                | Expr InfixOp Expr
                | "not" Expr
                | "some" VarList "in" Term

Term          ::= Ref
                | Var
                | Scalar
                | Array
                | Object
                | Set
                | Comprehension
                | "(" Term ")"

Ref           ::= Var (RefArg)*
RefArg        ::= "." Var | "[" Term "]"

Array         ::= "[" TermList? "]"
Object        ::= "{" ObjectItemList? "}"
Set           ::= "{" TermList "}"

Comprehension ::= ArrayComp | ObjectComp | SetComp
ArrayComp     ::= "[" Term "|" Body "]"
ObjectComp    ::= "{" Term ":" Term "|" Body "}"
SetComp       ::= "{" Term "|" Body "}"

Scalar        ::= String | Number | Boolean | Null
Boolean       ::= "true" | "false"
Null          ::= "null"

InfixOp       ::= "==" | "!=" | "<" | "<=" | ">" | ">="
                | "+" | "-" | "*" | "/" | "%"
                | "&" | "|"
```

### C. è°ƒè¯•å·¥å…·

**ASTå¯è§†åŒ–å·¥å…·**:

```go
// printAST: æ‰“å°ASTç»“æ„
func printAST(node interface{}, indent int) {
    prefix := strings.Repeat("  ", indent)
    
    switch n := node.(type) {
    case *Module:
        fmt.Printf("%sModule\n", prefix)
        printAST(n.Package, indent+1)
        for _, imp := range n.Imports {
            printAST(imp, indent+1)
        }
        for _, rule := range n.Rules {
            printAST(rule, indent+1)
        }
        
    case *Rule:
        fmt.Printf("%sRule\n", prefix)
        printAST(n.Head, indent+1)
        printAST(n.Body, indent+1)
        
    case *Head:
        fmt.Printf("%sHead: %s\n", prefix, n.Name)
        
    case Body:
        fmt.Printf("%sBody (%d exprs)\n", prefix, len(n))
        for _, expr := range n {
            printAST(expr, indent+1)
        }
        
    // ... å…¶ä»–èŠ‚ç‚¹ç±»å‹ ...
    }
}

// ä½¿ç”¨:
module, _ := ParseModule("example.rego", source)
printAST(module, 0)
```

**TokenæµæŸ¥çœ‹å™¨**:

```go
// showTokens: æ˜¾ç¤ºtokenæµ
func showTokens(source []byte) {
    s := newScanner(source)
    
    fmt.Println("TOKEN          VALUE          POS")
    fmt.Println("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    for {
        tok, val, pos := s.scan()
        
        fmt.Printf("%-12s   %-12s   %d:%d\n",
            tok.String(),
            val,
            pos.Row,
            pos.Col)
        
        if tok == EOF {
            break
        }
    }
}
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2025å¹´10æœˆ23æ—¥  
**ç»´æŠ¤è€…**: OPAæŠ€æœ¯æ–‡æ¡£é¡¹ç›®  
**åé¦ˆ**: æ¬¢è¿é€šè¿‡GitHub Issuesæä¾›å»ºè®®

**ç›¸å…³é˜…è¯»**:

- [OPAæ¶æ„æ€»è§ˆä¸ä»£ç ç»“æ„](10.1-OPAæ¶æ„æ€»è§ˆä¸ä»£ç ç»“æ„.md) - æ•´ä½“æ¶æ„
- [ASTæ„å»ºä¸è½¬æ¢](10.3-ASTæ„å»ºä¸è½¬æ¢.md) - ASTæ“ä½œè¯¦è§£
- [ç¼–è¯‘å™¨å®ç°è¯¦è§£](10.4-ç¼–è¯‘å™¨å®ç°è¯¦è§£.md) - ç¼–è¯‘ä¼˜åŒ–
- [Regoè¯­æ³•è§„èŒƒ](../02-è¯­è¨€æ¨¡å‹/02.1-Regoè¯­æ³•è§„èŒƒ.md) - è¯­æ³•å‚è€ƒ
